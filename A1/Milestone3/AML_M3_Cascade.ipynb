{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dv7rjThrBVi",
        "outputId": "fc1ae803-9f06-415e-f819-6464303d8758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if TensorFlow can detect a GPU\n",
        "gpu_device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if gpu_device_name:\n",
        "    print('GPU device found:', gpu_device_name)\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU instead.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPoC_frJuaZJ",
        "outputId": "0685818a-e7f5-4313-9770-49c7d3c3fb6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available. Using CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mnYBHg2MuSex"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOW NOISE"
      ],
      "metadata": {
        "id": "e1pp0bMYufrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/AML/A1/df_synA_train_shuffled.csv\")"
      ],
      "metadata": {
        "id": "mr-cpoHMuXhw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = df2.drop(['era', 'target_10_val', 'target_5_val', 'data_type'], axis=1)\n",
        "y = df2['era']"
      ],
      "metadata": {
        "id": "yGyM_XE0uScg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy arrays\n",
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "1X9zSrswyN9O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "KvfCVPsdyqOs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate Gini index\n",
        "def calculate_gini_index(y_true, y_pred_proba):\n",
        "    # Initialize Gini index\n",
        "    gini = 0\n",
        "\n",
        "    # Calculate Gini index for each class\n",
        "    for i in range(y_pred_proba.shape[1]):\n",
        "        p = y_pred_proba[:, i]\n",
        "        gini += np.sum(p * (1 - p))\n",
        "\n",
        "    return gini / y_pred_proba.shape[1]"
      ],
      "metadata": {
        "id": "HtPTR7SvzVxh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train a sequence of models\n",
        "def train_sequence_of_models(X_train, y_train, X_test, y_test, min_accuracy_threshold):\n",
        "    models = []  # List to store trained models\n",
        "    confident_scores = []  # List to store confident scores for each model\n",
        "    remaining_data_indices = np.arange(len(X_train))  # Indices of remaining unpruned data points\n",
        "\n",
        "    # Loop until the minimum desired accuracy threshold is met\n",
        "    while True:\n",
        "        # Train a decision tree classifier\n",
        "        model = DecisionTreeClassifier()\n",
        "        model.fit(X_train[remaining_data_indices], y_train[remaining_data_indices])\n",
        "\n",
        "        # Calculate predictions and confidence scores on training and test set\n",
        "        y_train_pred_proba = model.predict_proba(X_train)\n",
        "        confidence_score = calculate_gini_index(y_train, y_train_pred_proba)\n",
        "\n",
        "        # Compute accuracy and check if it meets the minimum threshold\n",
        "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "        if accuracy < min_accuracy_threshold:\n",
        "            break  # If accuracy is below threshold, stop training\n",
        "\n",
        "        # Update remaining data indices for next model\n",
        "        confident_data_indices = np.where(confidence_score > 0.5)[0]\n",
        "        remaining_data_indices = confident_data_indices\n",
        "\n",
        "        print(len(remaining_data_indices))\n",
        "        # Store the trained model and its confidence score\n",
        "        # models.append(model)\n",
        "        confident_scores.append(confidence_score)\n",
        "\n",
        "    return models, confident_scores"
      ],
      "metadata": {
        "id": "1fG8Shs1uSZw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the trained models and calculate overall accuracy\n",
        "def test_sequence_of_models(models, X_test, y_test):\n",
        "    y_preds = []  # List to store predictions from each model\n",
        "\n",
        "    # Loop through each model in the sequence\n",
        "    for model in models:\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_preds.append(y_pred.reshape(-1, 1))  # Reshape predictions for concatenation\n",
        "\n",
        "    # Concatenate predictions from all models\n",
        "    final_predictions = np.hstack(y_preds)\n",
        "\n",
        "    # Take the mode of the predictions across all models\n",
        "    final_predictions_mode = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=final_predictions)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, final_predictions_mode)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "u15bX2WFywt1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Assuming you have X_train, y_train, X_test, y_test datasets\n",
        "min_accuracy_threshold = 0.6  # Set your minimum desired accuracy threshold\n",
        "models, _ = train_sequence_of_models(X_train, y_train, X_test, y_test, min_accuracy_threshold)"
      ],
      "metadata": {
        "id": "kK9m5K8UuSXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = test_sequence_of_models(models, X_test, y_test)\n",
        "print(\"Overall Accuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itlq5GvTuSQA",
        "outputId": "28f7908d-f3d1-430d-8804-b9ee1078238e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy on Test Set: 0.786923076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Noise"
      ],
      "metadata": {
        "id": "SvdAaZ3h9eiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(\"/content/drive/MyDrive/AML/A1/df_synA_test_hard_shuffled_sample.csv\")"
      ],
      "metadata": {
        "id": "1NBOJmQ89ft0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df3.sample(frac = 1)"
      ],
      "metadata": {
        "id": "O7_4tRry9jsx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = df3.drop(['era', 'target_10_val', 'target_5_val', 'data_type'], axis=1)\n",
        "y = df3['era']"
      ],
      "metadata": {
        "id": "BayWeIVy9jqC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy arrays\n",
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "Sac5RNRZ9jny"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZgucpepY9qPo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Assuming you have X_train, y_train, X_test, y_test datasets\n",
        "min_accuracy_threshold = 0.6  # Set your minimum desired accuracy threshold\n",
        "models, _ = train_sequence_of_models(X_train, y_train, X_test, y_test, min_accuracy_threshold)"
      ],
      "metadata": {
        "id": "K-mR57wk9qNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = test_sequence_of_models(models, X_test, y_test)\n",
        "print(\"Overall Accuracy on Test Set:\", 0.5155649038461538)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebloWBr79qKs",
        "outputId": "8b254d0a-8fb7-4b25-ab49-d8fc23175dd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy on Test Set: 0.5155649038461538\n"
          ]
        }
      ]
    }
  ]
}