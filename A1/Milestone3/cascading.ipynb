{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard = pd.read_csv(\"C:/Users/Aaditya Gupta/OneDrive/Desktop/AML_A1_M3/df_synA_test_hard_shuffled_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>day</th>\n",
       "      <th>era</th>\n",
       "      <th>target_10_val</th>\n",
       "      <th>target_5_val</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>75</td>\n",
       "      <td>526</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>75</td>\n",
       "      <td>380</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>521</td>\n",
       "      <td>17</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>500</td>\n",
       "      <td>17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>75</td>\n",
       "      <td>467</td>\n",
       "      <td>22</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>75</td>\n",
       "      <td>474</td>\n",
       "      <td>15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>514</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>544</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>386</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>512</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  SMA_10_val  \\\n",
       "0         0.25        0.50       0.50          0.5           0.0        0.50   \n",
       "1         0.25        0.25       0.50          0.5           0.0        0.00   \n",
       "2         0.75        0.75       0.75          0.5           0.0        1.00   \n",
       "3         0.75        0.50       0.50          0.5           0.0        0.25   \n",
       "4         1.00        0.75       0.75          0.5           0.0        1.00   \n",
       "5         0.75        0.75       0.50          0.5           0.0        0.00   \n",
       "6         0.50        0.50       0.50          0.5           0.0        1.00   \n",
       "7         0.50        0.75       0.75          0.5           0.0        1.00   \n",
       "8         0.75        0.75       0.50          0.5           0.0        0.50   \n",
       "9         0.50        0.50       0.50          0.5           0.0        1.00   \n",
       "10        0.50        0.50       0.50          0.5           0.0        0.00   \n",
       "\n",
       "    SMA_20_val  CMO_14_val  High_n-Low_n_val  Open_n-Close_n_val  ...  \\\n",
       "0         1.00        0.00              0.50                0.00  ...   \n",
       "1         0.25        0.50              0.00                0.00  ...   \n",
       "2         1.00        0.00              0.00                1.00  ...   \n",
       "3         0.50        0.50              0.75                0.75  ...   \n",
       "4         1.00        0.00              0.50                1.00  ...   \n",
       "5         0.00        1.00              0.50                1.00  ...   \n",
       "6         1.00        0.25              0.00                0.25  ...   \n",
       "7         1.00        0.00              0.50                0.75  ...   \n",
       "8         0.25        0.75              1.00                1.00  ...   \n",
       "9         1.00        0.00              0.25                1.00  ...   \n",
       "10        0.00        0.75              0.25                0.75  ...   \n",
       "\n",
       "    SMA_20-SMA_10_changelen_val  Close_n_slope_3_changelen_val  \\\n",
       "0                          0.25                           1.00   \n",
       "1                          0.50                           1.00   \n",
       "2                          0.75                           0.25   \n",
       "3                          1.00                           0.00   \n",
       "4                          1.00                           0.25   \n",
       "5                          0.50                           0.75   \n",
       "6                          1.00                           1.00   \n",
       "7                          0.25                           1.00   \n",
       "8                          0.50                           0.50   \n",
       "9                          1.00                           0.00   \n",
       "10                         0.00                           0.50   \n",
       "\n",
       "    Close_n_slope_5_changelen_val  Close_n_slope_10_changelen_val  row_num  \\\n",
       "0                            1.00                            1.00       75   \n",
       "1                            1.00                            0.75       75   \n",
       "2                            0.00                            0.00       75   \n",
       "3                            0.00                            0.25       75   \n",
       "4                            0.25                            0.25       75   \n",
       "5                            1.00                            1.00       75   \n",
       "6                            0.75                            0.75       75   \n",
       "7                            0.50                            0.50       75   \n",
       "8                            0.50                            0.50       75   \n",
       "9                            0.00                            0.00       75   \n",
       "10                           0.50                            0.50       75   \n",
       "\n",
       "    day  era  target_10_val  target_5_val   data_type  \n",
       "0   526    7           1.00          1.00  validation  \n",
       "1   380   17           0.00          1.00  validation  \n",
       "2   521   17           0.75          0.75  validation  \n",
       "3   500   17           0.25          1.00  validation  \n",
       "4   488    0           0.75          1.00  validation  \n",
       "5   467   22           0.25          0.75  validation  \n",
       "6   474   15           1.00          1.00  validation  \n",
       "7   514    7           0.00          0.00  validation  \n",
       "8   544    8           1.00          0.75  validation  \n",
       "9   386    7           0.00          0.00  validation  \n",
       "10  512   14           0.00          0.00  validation  \n",
       "\n",
       "[11 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hard_ = df_hard.sort_values(by=['row_num'])\n",
    "df_hard_.reset_index(inplace = True)\n",
    "df_hard_ = df_hard_.drop(columns=['index'])\n",
    "df_hard_.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = df_hard_.drop(columns=['era','target_10_val'\t,'target_5_val',\t'data_type']), df_hard_['target_10_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.  , 0.75, 0.25, 0.5 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "y_=[]\n",
    "count=0\n",
    "for i in y:\n",
    "  if i not in d:\n",
    "    d[i]=count\n",
    "    count+=1\n",
    "  y_.append(d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_n_changelen_val</th>\n",
       "      <th>Close_n_changelen_val</th>\n",
       "      <th>High_n-Low_n_changelen_val</th>\n",
       "      <th>Open_n-Close_n_changelen_val</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>75</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>75</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249595</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>139</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249596</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>139</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249597</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>139</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249598</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>139</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249599</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>139</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249600 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  \\\n",
       "0             0.25        0.50       0.50         0.50           0.0   \n",
       "1             0.25        0.25       0.50         0.50           0.0   \n",
       "2             0.75        0.75       0.75         0.50           0.0   \n",
       "3             0.75        0.50       0.50         0.50           0.0   \n",
       "4             1.00        0.75       0.75         0.50           0.0   \n",
       "...            ...         ...        ...          ...           ...   \n",
       "249595        0.25        0.00       0.00         0.25           0.0   \n",
       "249596        0.75        0.75       0.75         0.75           0.0   \n",
       "249597        0.50        0.50       0.50         0.75           0.0   \n",
       "249598        0.00        0.00       0.00         0.00           0.0   \n",
       "249599        1.00        1.00       1.00         1.00           0.0   \n",
       "\n",
       "        SMA_10_val  SMA_20_val  CMO_14_val  High_n-Low_n_val  \\\n",
       "0             0.50        1.00        0.00              0.50   \n",
       "1             0.00        0.25        0.50              0.00   \n",
       "2             1.00        1.00        0.00              0.00   \n",
       "3             0.25        0.50        0.50              0.75   \n",
       "4             1.00        1.00        0.00              0.50   \n",
       "...            ...         ...         ...               ...   \n",
       "249595        0.00        0.00        0.50              0.00   \n",
       "249596        0.75        0.75        1.00              1.00   \n",
       "249597        1.00        0.75        0.50              0.75   \n",
       "249598        0.00        0.00        0.25              0.00   \n",
       "249599        1.00        1.00        0.75              0.25   \n",
       "\n",
       "        Open_n-Close_n_val  ...  Low_n_changelen_val  Close_n_changelen_val  \\\n",
       "0                     0.00  ...                 0.25                   0.75   \n",
       "1                     0.00  ...                 0.50                   0.50   \n",
       "2                     1.00  ...                 0.25                   0.00   \n",
       "3                     0.75  ...                 0.25                   0.00   \n",
       "4                     1.00  ...                 0.25                   0.25   \n",
       "...                    ...  ...                  ...                    ...   \n",
       "249595                0.50  ...                 0.25                   0.25   \n",
       "249596                0.50  ...                 1.00                   1.00   \n",
       "249597                0.25  ...                 0.00                   0.00   \n",
       "249598                0.75  ...                 1.00                   0.50   \n",
       "249599                0.25  ...                 0.75                   0.25   \n",
       "\n",
       "        High_n-Low_n_changelen_val  Open_n-Close_n_changelen_val  \\\n",
       "0                             0.25                          0.00   \n",
       "1                             0.00                          0.00   \n",
       "2                             0.00                          0.25   \n",
       "3                             0.25                          0.50   \n",
       "4                             0.25                          0.50   \n",
       "...                            ...                           ...   \n",
       "249595                        0.00                          0.50   \n",
       "249596                        0.75                          0.75   \n",
       "249597                        0.25                          0.25   \n",
       "249598                        0.00                          0.50   \n",
       "249599                        0.25                          0.25   \n",
       "\n",
       "        SMA_20-SMA_10_changelen_val  Close_n_slope_3_changelen_val  \\\n",
       "0                              0.25                           1.00   \n",
       "1                              0.50                           1.00   \n",
       "2                              0.75                           0.25   \n",
       "3                              1.00                           0.00   \n",
       "4                              1.00                           0.25   \n",
       "...                             ...                            ...   \n",
       "249595                         0.75                           0.25   \n",
       "249596                         0.50                           0.75   \n",
       "249597                         0.00                           0.50   \n",
       "249598                         0.75                           0.50   \n",
       "249599                         0.75                           0.50   \n",
       "\n",
       "        Close_n_slope_5_changelen_val  Close_n_slope_10_changelen_val  \\\n",
       "0                                1.00                            1.00   \n",
       "1                                1.00                            0.75   \n",
       "2                                0.00                            0.00   \n",
       "3                                0.00                            0.25   \n",
       "4                                0.25                            0.25   \n",
       "...                               ...                             ...   \n",
       "249595                           0.00                            0.25   \n",
       "249596                           0.25                            0.75   \n",
       "249597                           0.00                            0.25   \n",
       "249598                           0.50                            0.25   \n",
       "249599                           0.25                            0.25   \n",
       "\n",
       "        row_num  day  \n",
       "0            75  526  \n",
       "1            75  380  \n",
       "2            75  521  \n",
       "3            75  500  \n",
       "4            75  488  \n",
       "...         ...  ...  \n",
       "249595      139  376  \n",
       "249596      139  457  \n",
       "249597      139  431  \n",
       "249598      139  491  \n",
       "249599      139  512  \n",
       "\n",
       "[249600 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Noise mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your features in X and labels in y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y_ = np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((249600,), (249600, 26))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64766\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in y_:\n",
    "    if i==0:\n",
    "        n+=1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([1., 0., 0., 0., 0.], dtype=float32),\n",
       " 1: array([0., 1., 0., 0., 0.], dtype=float32),\n",
       " 2: array([0., 0., 1., 0., 0.], dtype=float32),\n",
       " 3: array([0., 0., 0., 1., 0.], dtype=float32),\n",
       " 4: array([0., 0., 0., 0., 1.], dtype=float32)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dic = {}\n",
    "for i in range(len(y_)):\n",
    "    if(y_[i] not in one_hot_dic):\n",
    "        one_hot_dic[y_[i]] = y_train_one_hot[i]\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_one_hot(y):\n",
    "    y_new=[]\n",
    "    for i in y:\n",
    "        for j in range(len(i)):\n",
    "            if(i[j]==1):\n",
    "                y_new.append(j)\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = []\n",
    "\n",
    "# Model 1\n",
    "input_shape=26\n",
    "num_classes=5\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 2\n",
    "model = Sequential([\n",
    "    Dense(16, activation='sigmoid', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='sigmoid'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 3\n",
    "model = Sequential([\n",
    "    Dense(16, activation='tanh', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='tanh'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 4\n",
    "model = Sequential([\n",
    "    Dense(20, input_shape=(26,)),\n",
    "    PReLU(),\n",
    "    Dense(10),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 5\n",
    "model = Sequential([\n",
    "    Dense(16, activation='tanh', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 6\n",
    "model = Sequential([\n",
    "    Dense(16, activation='linear', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 7\n",
    "model = Sequential([\n",
    "    Dense(16, activation='sigmoid', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 8\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='tanh'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 9\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(8, activation='sigmoid'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "# Model 10\n",
    "model = Sequential([\n",
    "    Dense(20, input_shape=(26,), activation='relu'),\n",
    "    Dense(10),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(20, input_shape=(26,)),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(10),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(26,)),\n",
    "    PReLU(),\n",
    "    Dense(8),\n",
    "    PReLU(),\n",
    "    Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_list.append(model)\n",
    "# Train and predict for each model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "# Define your neural network architecture\n",
    "\n",
    "\n",
    "def one_model(X,y_train_one_hot ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_train_one_hot, test_size=0.2, random_state=42)\n",
    "    # X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    model1 = models.Sequential([\n",
    "        layers.Dense(10, activation='relu', input_shape=(26,)),\n",
    "        # layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model1.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "    # Predict probabilities on test data\n",
    "    probabilities1 = model1.predict(X_test)\n",
    "    predicted_prob1 = np.max(probabilities1, axis=1)\n",
    "    predicted_label1 = np.argmax(probabilities1, axis=1)\n",
    "##########################################################################\n",
    "    l2_regularizer = tf.keras.regularizers.l2(0.01)\n",
    "    model2 = models.Sequential([\n",
    "        layers.Dense(10, activation='linear', input_shape=(26,), kernel_regularizer=l2_regularizer),\n",
    "        # layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    model2.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "    # Predict probabilities on test data\n",
    "    probabilities2 = model2.predict(X_test)\n",
    "    predicted_prob2 = np.max(probabilities2, axis=1)\n",
    "    predicted_label2 = np.argmax(probabilities2, axis=1)\n",
    "#############################################################################\n",
    "    model3 = models.Sequential([\n",
    "        layers.Dense(20, activation='tanh', input_shape=(26,)),\n",
    "        layers.Dense(10, activation='tanh'),\n",
    "        layers.Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model3.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model3.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "    # Predict probabilities on test data\n",
    "    probabilities3 = model3.predict(X_test)\n",
    "    predicted_prob3 = np.max(probabilities3, axis=1)\n",
    "    predicted_label3 = np.argmax(probabilities3, axis=1)\n",
    "##################################################################################\n",
    "    model4 = models.Sequential([\n",
    "        layers.Dense(20, input_shape=(26,)),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(10),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model4.compile(optimizer = 'adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model4.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "    # Predict probabilities on test data\n",
    "    probabilities4 = model4.predict(X_test)\n",
    "    predicted_prob4 = np.max(probabilities4, axis=1)\n",
    "    predicted_label4 = np.argmax(probabilities4, axis=1)\n",
    "    # Apply thresholding\n",
    "    # threshold = 0.5  # Adjust threshold as needed\n",
    "    # thresholded_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    # # Convert one-hot encoded predictions back to class labels if needed\n",
    "    # predicted_labels = np.argmax(thresholded_predictions, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # # Assume probabilities is the output of model.predict(X_test)\n",
    "\n",
    "    # # Apply thresholding\n",
    "    # threshold = 0.5  # Adjust threshold as needed\n",
    "    # thresholded_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "    # # Calculate maximum probability for each prediction\n",
    "    # max_probabilities = np.max(probabilities, axis=1)\n",
    "\n",
    "    # # Find indices where all class probabilities are below the threshold\n",
    "    # underconfident_indices = np.where(max_probabilities < threshold)[0]\n",
    "\n",
    "    # # Separate the underconfident data points\n",
    "    # underconfident_data_points = X_test[underconfident_indices]\n",
    "    # underconf_label = y_test[underconfident_indices]\n",
    "\n",
    "    \n",
    "    import joblib\n",
    "    joblib.dump(model1,\"C:/Users/Aaditya Gupta/OneDrive/Desktop/AML_A1_M3/model1.joblib\" )\n",
    "    joblib.dump(model2,\"C:/Users/Aaditya Gupta/OneDrive/Desktop/AML_A1_M3/model2.joblib\" )\n",
    "    # joblib.dump(model3,\"C:/Users/Aaditya Gupta/OneDrive/Desktop/AML_A1_M3/model3.joblib\" )\n",
    "    model1_cert = -np.sum(probabilities1 * np.log(probabilities1), axis=1)\n",
    "    model2_cert = -np.sum(probabilities2 * np.log(probabilities2), axis=1)\n",
    "    # model3_cert = -np.sum(probabilities3 * np.log(probabilities3), axis=1)\n",
    "    threshold = 0.56  # Adjust threshold based on desired trade-off between accuracy and coverage\n",
    "    '''\n",
    "    probabilities_list = []\n",
    "    predicted_prob_list = []\n",
    "    predicted_label_list = []\n",
    "\n",
    "    for i in range(len( models_list)):\n",
    "        print(models_list[i].summary())\n",
    "        models_list[i].fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "        probabilities = models_list[i].predict(X_test)\n",
    "        predicted_prob = np.max(probabilities, axis=1)\n",
    "        predicted_label = np.argmax(probabilities, axis=1)\n",
    "        probabilities_list.append(probabilities)\n",
    "        predicted_prob_list.append(predicted_prob)\n",
    "        predicted_label_list.append(predicted_label)\n",
    "    \n",
    "    threshold=0.56\n",
    "    X_uncert=[]\n",
    "    y_uncert=[]\n",
    "    preds=[]\n",
    "    X_cert=[]\n",
    "    y_cert=[]\n",
    "    # print(predicted_labels1, predicted_labels2,probabilities3)\n",
    "    # print(max(predicted_labels1[i], predicted_labels2[i]))\n",
    "    for i in range(len(X_test)):\n",
    "        max_prob = max(predicted_prob[i] for predicted_prob in predicted_prob_list)\n",
    "        if max_prob > threshold:\n",
    "            # Select classifier with higher certainty\n",
    "            for j, predicted_prob in enumerate(predicted_prob_list):\n",
    "                if max_prob == predicted_prob[i]:\n",
    "                    prediction = predicted_label_list[j][i]\n",
    "                    break\n",
    "        else:\n",
    "            X_uncert.append(X_test[i])\n",
    "            y_uncert.append(y_test[i])\n",
    "            continue\n",
    "        X_cert.append(X_test[i])\n",
    "        y_cert.append(y_test[i])\n",
    "        preds.append(prediction)\n",
    "    y_cert_ = rev_one_hot(y_cert)\n",
    "    # print(len(y_test),len(y_cert), len(y_uncert))\n",
    "    cm = confusion_matrix(y_cert_, preds)\n",
    "\n",
    "    # Plot confusion matrix with colors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    print(classification_report(y_cert_, preds))\n",
    "    X_uncert, y_uncert = np.array(X_uncert), np.array(y_uncert)\n",
    "    return y_cert, preds, X_uncert, y_uncert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_list)):\n",
    "    print(models_list[i].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.5233 - accuracy: 0.2592\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4435 - accuracy: 0.2581\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.7720 - accuracy: 0.1120\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.6524 - accuracy: 0.3481\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.5748 - accuracy: 0.2474\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.7316 - accuracy: 0.4154\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 10s 1ms/step - loss: 1.4620 - accuracy: 0.2550\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 10s 1ms/step - loss: 1.4341 - accuracy: 0.2536\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.4373 - accuracy: 0.2570\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 4.0427 - accuracy: 0.2250\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 7.8685 - accuracy: 0.2675\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.7395 - accuracy: 0.2446\n",
      "1560/1560 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.51      7029\n",
      "           1       0.47      0.77      0.58      8627\n",
      "           2       0.53      0.31      0.39      6528\n",
      "           3       0.85      0.17      0.28      6134\n",
      "           4       0.00      0.00      0.00       264\n",
      "\n",
      "    accuracy                           0.49     28582\n",
      "   macro avg       0.46      0.37      0.35     28582\n",
      "weighted avg       0.56      0.49      0.45     28582\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "x,a,b,c=one_model(X, y_train_one_hot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ = np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade(X,y_train_one_hot,Y_TEST,Y_PRED):\n",
    "    if(len(X)<=30 or len(y_train_one_hot)<=30):\n",
    "        return Y_TEST,Y_PRED\n",
    "    y1,p1,b,c=one_model(X, y_train_one_hot)\n",
    "    Y_TEST.append(y1)\n",
    "    Y_PRED.append(p1)\n",
    "    print(len(p1), len(y1))\n",
    "    return cascade(b,c,Y_TEST,Y_PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2591\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2591\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2591\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 14s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2581\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2588\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2582\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2590\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2581\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2588\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2582\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2589\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2583\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2579\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2590\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2584\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2588\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2585\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2589\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2592\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2584\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2584\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2586\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2584\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2593\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2593\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2584\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2585\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2593\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2595\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2587\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2591\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2590\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2589\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2593\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2592\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.6361 - accuracy: 0.2441\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.5540 - accuracy: 0.2441\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.5077 - accuracy: 0.2441\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4820 - accuracy: 0.2441\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4668 - accuracy: 0.2441\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4572 - accuracy: 0.2441\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4509 - accuracy: 0.2441\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4466 - accuracy: 0.2540\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4436 - accuracy: 0.2594\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4414 - accuracy: 0.2594\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4398 - accuracy: 0.2594\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4385 - accuracy: 0.2594\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4376 - accuracy: 0.2594\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4368 - accuracy: 0.2594\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4362 - accuracy: 0.2594\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4357 - accuracy: 0.2594\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4353 - accuracy: 0.2594\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4349 - accuracy: 0.2594\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4347 - accuracy: 0.2594\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4344 - accuracy: 0.2594\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4342 - accuracy: 0.2594\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4341 - accuracy: 0.2594\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4339 - accuracy: 0.2594\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4338 - accuracy: 0.2594\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4337 - accuracy: 0.2594\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4336 - accuracy: 0.2594\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4335 - accuracy: 0.2594\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4334 - accuracy: 0.2594\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4333 - accuracy: 0.2594\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4333 - accuracy: 0.2594\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4332 - accuracy: 0.2594\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4332 - accuracy: 0.2594\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4332 - accuracy: 0.2594\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2594\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2594\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2594\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2594\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2594\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2594\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2594\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3498 - accuracy: 0.4362\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2548 - accuracy: 0.4787\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1959 - accuracy: 0.5056\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1506 - accuracy: 0.5283\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1176 - accuracy: 0.5410\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0945 - accuracy: 0.5496\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0772 - accuracy: 0.5556\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0619 - accuracy: 0.5614\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0484 - accuracy: 0.5662\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0368 - accuracy: 0.5699\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0284 - accuracy: 0.5743\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0211 - accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0154 - accuracy: 0.5799\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0106 - accuracy: 0.5821\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0068 - accuracy: 0.5829\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0029 - accuracy: 0.5844\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 0.9982 - accuracy: 0.5849\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 0.9948 - accuracy: 0.5881\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9912 - accuracy: 0.5892\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9880 - accuracy: 0.5897\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9859 - accuracy: 0.5921\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9832 - accuracy: 0.5930\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9813 - accuracy: 0.5934\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9787 - accuracy: 0.5942\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9762 - accuracy: 0.5947\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9749 - accuracy: 0.5966\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9731 - accuracy: 0.5966\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9713 - accuracy: 0.5978\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9700 - accuracy: 0.5983\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9685 - accuracy: 0.5979\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9670 - accuracy: 0.5984\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9654 - accuracy: 0.5995\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9642 - accuracy: 0.5997\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9626 - accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9616 - accuracy: 0.5999\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9602 - accuracy: 0.6015\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9596 - accuracy: 0.6013\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9591 - accuracy: 0.6016\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9569 - accuracy: 0.6018\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9564 - accuracy: 0.6023\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9549 - accuracy: 0.6034\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9538 - accuracy: 0.6026\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9532 - accuracy: 0.6027\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9519 - accuracy: 0.6034\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9507 - accuracy: 0.6044\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9500 - accuracy: 0.6046\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9483 - accuracy: 0.6038\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9474 - accuracy: 0.6041\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9474 - accuracy: 0.6054\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9469 - accuracy: 0.6046\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9451 - accuracy: 0.6058\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9442 - accuracy: 0.6058\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9441 - accuracy: 0.6057\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9432 - accuracy: 0.6068\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9425 - accuracy: 0.6063\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9419 - accuracy: 0.6062\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9411 - accuracy: 0.6066\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9410 - accuracy: 0.6071\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9402 - accuracy: 0.6081\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9403 - accuracy: 0.6079\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9393 - accuracy: 0.6076\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9395 - accuracy: 0.6081\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9382 - accuracy: 0.6087\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9376 - accuracy: 0.6078\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9374 - accuracy: 0.6087\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9373 - accuracy: 0.6091\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9369 - accuracy: 0.6089\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9364 - accuracy: 0.6090\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9361 - accuracy: 0.6097\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9355 - accuracy: 0.6100\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9344 - accuracy: 0.6108\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9345 - accuracy: 0.6104\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9340 - accuracy: 0.6089\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9336 - accuracy: 0.6104\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9337 - accuracy: 0.6100\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9326 - accuracy: 0.6107\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9325 - accuracy: 0.6109\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9321 - accuracy: 0.6111\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9318 - accuracy: 0.6108\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9307 - accuracy: 0.6113\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9305 - accuracy: 0.6129\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9304 - accuracy: 0.6114\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9304 - accuracy: 0.6115\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9291 - accuracy: 0.6115\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9289 - accuracy: 0.6132\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9281 - accuracy: 0.6124\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9280 - accuracy: 0.6123\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9280 - accuracy: 0.6110\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9269 - accuracy: 0.6128\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9268 - accuracy: 0.6134\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9257 - accuracy: 0.6136\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9258 - accuracy: 0.6131\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9250 - accuracy: 0.6132\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 0.9257 - accuracy: 0.6130\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9254 - accuracy: 0.6136\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9250 - accuracy: 0.6137\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9242 - accuracy: 0.6141\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9243 - accuracy: 0.6153\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9237 - accuracy: 0.6138\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 0.9238 - accuracy: 0.6141\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.5098 - accuracy: 0.2533\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4796 - accuracy: 0.2594\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4613 - accuracy: 0.2594\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4503 - accuracy: 0.2594\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4437 - accuracy: 0.2594\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4398 - accuracy: 0.2594\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4374 - accuracy: 0.2594\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4359 - accuracy: 0.2594\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4350 - accuracy: 0.2594\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4343 - accuracy: 0.2594\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4339 - accuracy: 0.2594\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4336 - accuracy: 0.2594\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4333 - accuracy: 0.2594\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4332 - accuracy: 0.2594\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2594\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2594\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4327 - accuracy: 0.2594\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2524 - accuracy: 0.4857\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2346 - accuracy: 0.4904\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2239 - accuracy: 0.4956\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2165 - accuracy: 0.4979\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2107 - accuracy: 0.5002\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2039 - accuracy: 0.5027\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2004 - accuracy: 0.5044\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1977 - accuracy: 0.5060\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1948 - accuracy: 0.5079\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1888 - accuracy: 0.5112\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1855 - accuracy: 0.5130\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1784 - accuracy: 0.5146\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1708 - accuracy: 0.5168\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1654 - accuracy: 0.5186\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1582 - accuracy: 0.5206\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1447 - accuracy: 0.5282\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1342 - accuracy: 0.5351\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1236 - accuracy: 0.5437\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1164 - accuracy: 0.5478\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1105 - accuracy: 0.5511\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1062 - accuracy: 0.5522\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.1022 - accuracy: 0.5539\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0994 - accuracy: 0.5555\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0966 - accuracy: 0.5557\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0945 - accuracy: 0.5565\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0922 - accuracy: 0.5582\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0909 - accuracy: 0.5583\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0893 - accuracy: 0.5590\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0891 - accuracy: 0.5589\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0873 - accuracy: 0.5599\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0860 - accuracy: 0.5601\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0859 - accuracy: 0.5599\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0839 - accuracy: 0.5613\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0840 - accuracy: 0.5602\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0828 - accuracy: 0.5615\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0815 - accuracy: 0.5628\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0804 - accuracy: 0.5629\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0769 - accuracy: 0.5639\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0747 - accuracy: 0.5638\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0728 - accuracy: 0.5639\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0700 - accuracy: 0.5646\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0676 - accuracy: 0.5664\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0648 - accuracy: 0.5671\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0633 - accuracy: 0.5683\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0619 - accuracy: 0.5691\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0596 - accuracy: 0.5699\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0598 - accuracy: 0.5688\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0583 - accuracy: 0.5698\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0576 - accuracy: 0.5693\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0569 - accuracy: 0.5700\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0555 - accuracy: 0.5706\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0559 - accuracy: 0.5704\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0553 - accuracy: 0.5704\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0541 - accuracy: 0.5703\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0542 - accuracy: 0.5709\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0528 - accuracy: 0.5719\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0527 - accuracy: 0.5711\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0525 - accuracy: 0.5719\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0516 - accuracy: 0.5717\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0517 - accuracy: 0.5729\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0507 - accuracy: 0.5722\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0510 - accuracy: 0.5722\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0506 - accuracy: 0.5722\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0496 - accuracy: 0.5724\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0499 - accuracy: 0.5723\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0487 - accuracy: 0.5728\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0492 - accuracy: 0.5719\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0483 - accuracy: 0.5722\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0484 - accuracy: 0.5729\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0477 - accuracy: 0.5738\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0481 - accuracy: 0.5729\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0472 - accuracy: 0.5731\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0449 - accuracy: 0.5737\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0431 - accuracy: 0.5747\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0413 - accuracy: 0.5747\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0400 - accuracy: 0.5753\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0396 - accuracy: 0.5747\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0377 - accuracy: 0.5757\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0368 - accuracy: 0.5753\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0358 - accuracy: 0.5757\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0345 - accuracy: 0.5766\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0329 - accuracy: 0.5765\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0322 - accuracy: 0.5771\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0314 - accuracy: 0.5778\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0301 - accuracy: 0.5778\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0291 - accuracy: 0.5775\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0284 - accuracy: 0.5782\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0274 - accuracy: 0.5792\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0260 - accuracy: 0.5798\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0253 - accuracy: 0.5794\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0246 - accuracy: 0.5792\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0243 - accuracy: 0.5792\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0237 - accuracy: 0.5800\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0231 - accuracy: 0.5799\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0224 - accuracy: 0.5800\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0217 - accuracy: 0.5807\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0208 - accuracy: 0.5802\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0201 - accuracy: 0.5808\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0200 - accuracy: 0.5812\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.0190 - accuracy: 0.5808\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2592\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2593\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4329 - accuracy: 0.2594\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4328 - accuracy: 0.2594\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 14s 2ms/step - loss: 1.4335 - accuracy: 0.2553\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2546\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2535\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2556\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2555\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2546\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2554\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2543\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2563\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2551\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2548\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2544\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2554\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2542\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2543\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2547\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2552\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2548\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2541\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2542\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2535\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2555\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2550\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2553\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2558\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2546\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2551\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2548\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2563\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2536\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2555\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2543\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2553\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2553\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2559\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2536\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2551\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2544\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2545\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2554\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2536\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2546\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2533\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2547\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2549\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2534\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2554\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2543\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2538\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2541\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2543\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2538\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2533\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4336 - accuracy: 0.2543\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2545\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2533\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2544\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2554\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2549\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2543\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2540\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2534\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2540\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2544\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2554\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2544\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2554\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2548\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2532\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2550\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2533\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4336 - accuracy: 0.2546\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2553\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2541\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2555\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2546\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2542\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2553\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2548\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2554\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2549\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2538\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2541\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2543\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4336 - accuracy: 0.2534\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2547\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2535\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2547\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2553\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4334 - accuracy: 0.2545\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2543\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4334 - accuracy: 0.2557\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4335 - accuracy: 0.2536\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2549\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.4335 - accuracy: 0.2544\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2576\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2585\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2572\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2576\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2576\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2585\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2574\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2578\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2570\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2575\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2575\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2578\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2582\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2578\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2584\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2571\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2585\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2587\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2579\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4329 - accuracy: 0.2577\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2581\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2576\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2587\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2578\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2586\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2585\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2588\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4332 - accuracy: 0.2575\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2580\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2577\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2578\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2578\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4333 - accuracy: 0.2574\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2576\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2580\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2588\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2582\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2584\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4331 - accuracy: 0.2581\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2583\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4341 - accuracy: 0.2580\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4330 - accuracy: 0.2588\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4329 - accuracy: 0.2588\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.6674 - accuracy: 0.2786\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.5064 - accuracy: 0.3101\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4527 - accuracy: 0.3365\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4236 - accuracy: 0.3564\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4031 - accuracy: 0.3696\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3875 - accuracy: 0.3805\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3749 - accuracy: 0.3919\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3646 - accuracy: 0.4016\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3561 - accuracy: 0.4104\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3489 - accuracy: 0.4188\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3428 - accuracy: 0.4262\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3375 - accuracy: 0.4333\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3327 - accuracy: 0.4393\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3286 - accuracy: 0.4447\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3250 - accuracy: 0.4497\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3217 - accuracy: 0.4546\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3187 - accuracy: 0.4575\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3161 - accuracy: 0.4609\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3136 - accuracy: 0.4630\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3113 - accuracy: 0.4658\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3094 - accuracy: 0.4676\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3075 - accuracy: 0.4699\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3057 - accuracy: 0.4711\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3040 - accuracy: 0.4726\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3025 - accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3011 - accuracy: 0.4745\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2997 - accuracy: 0.4751\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2985 - accuracy: 0.4765\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2972 - accuracy: 0.4768\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2961 - accuracy: 0.4775\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2950 - accuracy: 0.4780\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2940 - accuracy: 0.4791\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2930 - accuracy: 0.4793\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2921 - accuracy: 0.4799\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2912 - accuracy: 0.4805\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2903 - accuracy: 0.4810\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2896 - accuracy: 0.4817\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2888 - accuracy: 0.4815\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2880 - accuracy: 0.4825\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2873 - accuracy: 0.4830\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2866 - accuracy: 0.4825\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2860 - accuracy: 0.4829\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2853 - accuracy: 0.4828\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2847 - accuracy: 0.4833\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2841 - accuracy: 0.4836\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2835 - accuracy: 0.4833\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2830 - accuracy: 0.4833\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2824 - accuracy: 0.4837\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2818 - accuracy: 0.4839\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2813 - accuracy: 0.4842\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2808 - accuracy: 0.4844\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2803 - accuracy: 0.4844\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2798 - accuracy: 0.4844\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.2793 - accuracy: 0.4839\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 13s 2ms/step - loss: 1.2789 - accuracy: 0.4843\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2784 - accuracy: 0.4849\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2781 - accuracy: 0.4848\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2776 - accuracy: 0.4851\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2772 - accuracy: 0.4847\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2768 - accuracy: 0.4848\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2764 - accuracy: 0.4849\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2760 - accuracy: 0.4851\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2756 - accuracy: 0.4851\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2753 - accuracy: 0.4852\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2749 - accuracy: 0.4856\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2745 - accuracy: 0.4856\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2742 - accuracy: 0.4854\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2739 - accuracy: 0.4859\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2735 - accuracy: 0.4855\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2732 - accuracy: 0.4858\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2729 - accuracy: 0.4863\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2725 - accuracy: 0.4860\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2723 - accuracy: 0.4860\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2720 - accuracy: 0.4865\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2717 - accuracy: 0.4869\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2713 - accuracy: 0.4865\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2711 - accuracy: 0.4867\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2708 - accuracy: 0.4869\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2705 - accuracy: 0.4870\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2702 - accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2699 - accuracy: 0.4869\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2696 - accuracy: 0.4872\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2694 - accuracy: 0.4874\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2691 - accuracy: 0.4876\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2689 - accuracy: 0.4875\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2686 - accuracy: 0.4878\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2684 - accuracy: 0.4874\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2681 - accuracy: 0.4877\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2679 - accuracy: 0.4879\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2677 - accuracy: 0.4876\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2675 - accuracy: 0.4878\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2672 - accuracy: 0.4887\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2670 - accuracy: 0.4884\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2668 - accuracy: 0.4882\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2666 - accuracy: 0.4886\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2663 - accuracy: 0.4888\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2661 - accuracy: 0.4884\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2659 - accuracy: 0.4890\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2657 - accuracy: 0.4891\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2655 - accuracy: 0.4892\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.6886 - accuracy: 0.3259\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4097 - accuracy: 0.3870\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3694 - accuracy: 0.4274\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3552 - accuracy: 0.4469\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3453 - accuracy: 0.4561\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3371 - accuracy: 0.4626\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3299 - accuracy: 0.4677\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3236 - accuracy: 0.4709\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3179 - accuracy: 0.4739\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3128 - accuracy: 0.4764\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3081 - accuracy: 0.4794\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3038 - accuracy: 0.4814\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3000 - accuracy: 0.4825\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2964 - accuracy: 0.4847\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2932 - accuracy: 0.4857\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2902 - accuracy: 0.4877\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2874 - accuracy: 0.4888\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2848 - accuracy: 0.4904\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2824 - accuracy: 0.4916\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2802 - accuracy: 0.4927\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2781 - accuracy: 0.4937\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2761 - accuracy: 0.4950\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2743 - accuracy: 0.4959\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2726 - accuracy: 0.4968\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2710 - accuracy: 0.4975\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2694 - accuracy: 0.4987\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2680 - accuracy: 0.4994\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2666 - accuracy: 0.4998\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2653 - accuracy: 0.5003\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2641 - accuracy: 0.5012\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2629 - accuracy: 0.5014\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2618 - accuracy: 0.5019\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2607 - accuracy: 0.5024\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2598 - accuracy: 0.5027\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2588 - accuracy: 0.5032\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2579 - accuracy: 0.5034\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2570 - accuracy: 0.5039\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2561 - accuracy: 0.5042\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2552 - accuracy: 0.5045\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2545 - accuracy: 0.5048\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2537 - accuracy: 0.5051\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2530 - accuracy: 0.5049\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2522 - accuracy: 0.5055\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2515 - accuracy: 0.5051\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2509 - accuracy: 0.5059\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2502 - accuracy: 0.5059\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2496 - accuracy: 0.5060\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2490 - accuracy: 0.5059\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2484 - accuracy: 0.5062\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2478 - accuracy: 0.5066\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2472 - accuracy: 0.5068\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2467 - accuracy: 0.5069\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2462 - accuracy: 0.5067\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2457 - accuracy: 0.5072\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2451 - accuracy: 0.5071\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2447 - accuracy: 0.5074\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2442 - accuracy: 0.5073\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2437 - accuracy: 0.5076\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2432 - accuracy: 0.5078\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2428 - accuracy: 0.5083\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2423 - accuracy: 0.5076\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2419 - accuracy: 0.5081\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2415 - accuracy: 0.5079\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2411 - accuracy: 0.5081\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2407 - accuracy: 0.5083\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2403 - accuracy: 0.5081\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2399 - accuracy: 0.5081\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2395 - accuracy: 0.5086\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2392 - accuracy: 0.5086\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2388 - accuracy: 0.5087\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2384 - accuracy: 0.5087\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2380 - accuracy: 0.5085\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2377 - accuracy: 0.5090\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2374 - accuracy: 0.5090\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2371 - accuracy: 0.5089\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2367 - accuracy: 0.5093\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2364 - accuracy: 0.5092\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2361 - accuracy: 0.5093\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2357 - accuracy: 0.5088\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2354 - accuracy: 0.5095\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2352 - accuracy: 0.5093\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2348 - accuracy: 0.5093\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2346 - accuracy: 0.5097\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2342 - accuracy: 0.5096\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2340 - accuracy: 0.5099\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2337 - accuracy: 0.5096\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2335 - accuracy: 0.5099\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2331 - accuracy: 0.5100\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2328 - accuracy: 0.5097\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2326 - accuracy: 0.5096\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2323 - accuracy: 0.5103\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2321 - accuracy: 0.5102\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2318 - accuracy: 0.5100\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2315 - accuracy: 0.5104\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2313 - accuracy: 0.5104\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.2311 - accuracy: 0.5104\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2308 - accuracy: 0.5104\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2306 - accuracy: 0.5107\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2303 - accuracy: 0.5106\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.2301 - accuracy: 0.5107\n",
      "1560/1560 [==============================] - 2s 1ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4378 - accuracy: 0.2690\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4201 - accuracy: 0.2978\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4101 - accuracy: 0.3239\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.4033 - accuracy: 0.3450\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3983 - accuracy: 0.3597\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3942 - accuracy: 0.3676\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3906 - accuracy: 0.3726\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3876 - accuracy: 0.3763\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3849 - accuracy: 0.3784\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3826 - accuracy: 0.3797\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3803 - accuracy: 0.3807\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3783 - accuracy: 0.3815\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3764 - accuracy: 0.3829\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3747 - accuracy: 0.3834\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3730 - accuracy: 0.3829\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3715 - accuracy: 0.3832\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3700 - accuracy: 0.3843\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3686 - accuracy: 0.3846\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3673 - accuracy: 0.3847\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3661 - accuracy: 0.3852\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3649 - accuracy: 0.3844\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3638 - accuracy: 0.3847\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3627 - accuracy: 0.3852\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3617 - accuracy: 0.3839\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3606 - accuracy: 0.3852\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3597 - accuracy: 0.3846\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3588 - accuracy: 0.3846\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3579 - accuracy: 0.3849\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3570 - accuracy: 0.3848\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3561 - accuracy: 0.3859\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3554 - accuracy: 0.3852\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3546 - accuracy: 0.3857\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3539 - accuracy: 0.3855\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3532 - accuracy: 0.3858\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3524 - accuracy: 0.3857\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3517 - accuracy: 0.3856\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3511 - accuracy: 0.3857\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3504 - accuracy: 0.3858\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3498 - accuracy: 0.3864\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3492 - accuracy: 0.3860\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3486 - accuracy: 0.3861\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3480 - accuracy: 0.3864\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3474 - accuracy: 0.3866\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3469 - accuracy: 0.3863\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3463 - accuracy: 0.3867\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3458 - accuracy: 0.3869\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3453 - accuracy: 0.3869\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3448 - accuracy: 0.3868\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3443 - accuracy: 0.3873\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3438 - accuracy: 0.3877\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3433 - accuracy: 0.3874\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3429 - accuracy: 0.3870\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3424 - accuracy: 0.3876\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3420 - accuracy: 0.3874\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3416 - accuracy: 0.3873\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3411 - accuracy: 0.3883\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3407 - accuracy: 0.3880\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3403 - accuracy: 0.3885\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3399 - accuracy: 0.3886\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3395 - accuracy: 0.3878\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3391 - accuracy: 0.3885\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3387 - accuracy: 0.3887\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3384 - accuracy: 0.3891\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3380 - accuracy: 0.3890\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3377 - accuracy: 0.3888\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3373 - accuracy: 0.3892\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3370 - accuracy: 0.3899\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3367 - accuracy: 0.3897\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3363 - accuracy: 0.3893\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3360 - accuracy: 0.3902\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3357 - accuracy: 0.3902\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3354 - accuracy: 0.3901\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3351 - accuracy: 0.3901\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3347 - accuracy: 0.3902\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3345 - accuracy: 0.3908\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3342 - accuracy: 0.3909\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3339 - accuracy: 0.3910\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3336 - accuracy: 0.3909\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3333 - accuracy: 0.3914\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3330 - accuracy: 0.3915\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3327 - accuracy: 0.3916\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3325 - accuracy: 0.3916\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3322 - accuracy: 0.3920\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3320 - accuracy: 0.3913\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3317 - accuracy: 0.3921\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3315 - accuracy: 0.3920\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3312 - accuracy: 0.3922\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3310 - accuracy: 0.3927\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3307 - accuracy: 0.3927\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3305 - accuracy: 0.3928\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3302 - accuracy: 0.3930\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3300 - accuracy: 0.3933\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3298 - accuracy: 0.3934\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 12s 2ms/step - loss: 1.3296 - accuracy: 0.3931\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3293 - accuracy: 0.3940\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3291 - accuracy: 0.3941\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3289 - accuracy: 0.3942\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3287 - accuracy: 0.3945\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3284 - accuracy: 0.3948\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3282 - accuracy: 0.3946\n",
      "1560/1560 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      8704\n",
      "           1       0.74      0.88      0.81      8559\n",
      "           2       0.77      0.61      0.68      5616\n",
      "           3       0.72      0.58      0.64      5661\n",
      "           4       0.00      0.00      0.00       202\n",
      "\n",
      "    accuracy                           0.76     28742\n",
      "   macro avg       0.60      0.59      0.59     28742\n",
      "weighted avg       0.75      0.76      0.75     28742\n",
      "\n",
      "28742 28742\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 2s 2ms/step - loss: 1.4313 - accuracy: 0.3006\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3021\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4187 - accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3082\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3086\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3089\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3082\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3082\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3074\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3038\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3076\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3066\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3090\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3078\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3075\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3083\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3074\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3070\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3092\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3076\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3060\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3090\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3091\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3108\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3084\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3061\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3079\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3049\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3101\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3058\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3102\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3075\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3090\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3069\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3075\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3087\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3063\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3046\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3057\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3083\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3096\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3024\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3086\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3078\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3095\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3028\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3093\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3065\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3091\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3059\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3082\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3074\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3072\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3083\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3076\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3039\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3091\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3095\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3092\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3096\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3069\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4260 - accuracy: 0.3071\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4196 - accuracy: 0.3070\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3057\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.3034\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3070\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3121\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3022\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3060\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3069\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3086\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3101\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3060\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3083\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3108\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3087\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3079\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3040\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3066\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3101\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3091\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3085\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3073\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3098\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3069\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3103\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3100\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3062\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3083\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3027\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3056\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3074\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3093\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3069\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3111\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3078\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3088\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3061\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3033\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4183 - accuracy: 0.3119\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3083\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3091\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3062\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3095\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3036\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3070\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3104\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3066\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3073\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3063\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3070\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3078\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3052\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3089\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3079\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3060\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3064\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3100\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3066\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3051\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3046\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3079\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3067\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3089\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3078\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3085\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3108\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3036\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3093\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3076\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3081\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3065\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3059\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3081\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3127\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3086\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3063\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3071\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3116\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3078\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3088\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3082\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3069\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3052\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3065\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3075\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3106\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3073\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3079\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3100\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3102\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3102\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3081\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3084\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3099\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3029\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4558 - accuracy: 0.2030\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4533 - accuracy: 0.2030\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4511 - accuracy: 0.2337\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4490 - accuracy: 0.3058\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4472 - accuracy: 0.3058\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4454 - accuracy: 0.3058\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4438 - accuracy: 0.3058\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4423 - accuracy: 0.3058\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4409 - accuracy: 0.3058\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4396 - accuracy: 0.3058\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4383 - accuracy: 0.3058\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4372 - accuracy: 0.3058\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4361 - accuracy: 0.3058\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4351 - accuracy: 0.3058\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4342 - accuracy: 0.3058\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4334 - accuracy: 0.3058\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4326 - accuracy: 0.3058\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4318 - accuracy: 0.3058\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4311 - accuracy: 0.3058\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4304 - accuracy: 0.3058\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4298 - accuracy: 0.3058\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4292 - accuracy: 0.3058\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4287 - accuracy: 0.3058\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4282 - accuracy: 0.3058\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4277 - accuracy: 0.3058\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.3058\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4268 - accuracy: 0.3058\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4264 - accuracy: 0.3058\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4260 - accuracy: 0.3058\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4257 - accuracy: 0.3058\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4253 - accuracy: 0.3058\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4250 - accuracy: 0.3058\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4247 - accuracy: 0.3058\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4244 - accuracy: 0.3058\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4242 - accuracy: 0.3058\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4239 - accuracy: 0.3058\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4237 - accuracy: 0.3058\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4234 - accuracy: 0.3058\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4232 - accuracy: 0.3058\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4230 - accuracy: 0.3058\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4228 - accuracy: 0.3058\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4226 - accuracy: 0.3058\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4224 - accuracy: 0.3058\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4223 - accuracy: 0.3058\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4221 - accuracy: 0.3058\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4219 - accuracy: 0.3058\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4218 - accuracy: 0.3058\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4216 - accuracy: 0.3058\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4215 - accuracy: 0.3058\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4214 - accuracy: 0.3058\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4213 - accuracy: 0.3058\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4211 - accuracy: 0.3058\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4210 - accuracy: 0.3058\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4209 - accuracy: 0.3058\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4208 - accuracy: 0.3058\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4207 - accuracy: 0.3058\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4206 - accuracy: 0.3058\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4205 - accuracy: 0.3058\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4205 - accuracy: 0.3058\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4204 - accuracy: 0.3058\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4203 - accuracy: 0.3058\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4202 - accuracy: 0.3058\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4202 - accuracy: 0.3058\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4201 - accuracy: 0.3058\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4200 - accuracy: 0.3058\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4200 - accuracy: 0.3058\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4199 - accuracy: 0.3058\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4199 - accuracy: 0.3058\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4198 - accuracy: 0.3058\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4198 - accuracy: 0.3058\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4197 - accuracy: 0.3058\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4197 - accuracy: 0.3058\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4196 - accuracy: 0.3058\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4196 - accuracy: 0.3058\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4195 - accuracy: 0.3058\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4195 - accuracy: 0.3058\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4195 - accuracy: 0.3058\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3058\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3058\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3058\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3058\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3058\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3058\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3058\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3058\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3058\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3058\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3058\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3058\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3058\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3058\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3058\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3058\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3058\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3058\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 2s 2ms/step - loss: 1.2975 - accuracy: 0.4062\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2910 - accuracy: 0.4047\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2877 - accuracy: 0.4148\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2859 - accuracy: 0.4070\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2862 - accuracy: 0.4116\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2839 - accuracy: 0.4117\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2801 - accuracy: 0.4126\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2818 - accuracy: 0.4131\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2816 - accuracy: 0.4158\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2792 - accuracy: 0.4193\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2806 - accuracy: 0.4161\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2805 - accuracy: 0.4161\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2791 - accuracy: 0.4181\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2772 - accuracy: 0.4168\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2787 - accuracy: 0.4144\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2786 - accuracy: 0.4154\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2758 - accuracy: 0.4198\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2762 - accuracy: 0.4183\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2762 - accuracy: 0.4144\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2740 - accuracy: 0.4195\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2742 - accuracy: 0.4194\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2748 - accuracy: 0.4206\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2747 - accuracy: 0.4217\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2754 - accuracy: 0.4182\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2731 - accuracy: 0.4198\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2733 - accuracy: 0.4176\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2746 - accuracy: 0.4230\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2734 - accuracy: 0.4204\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2717 - accuracy: 0.4207\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2738 - accuracy: 0.4197\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2712 - accuracy: 0.4166\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2718 - accuracy: 0.4214\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2722 - accuracy: 0.4188\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2709 - accuracy: 0.4226\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2721 - accuracy: 0.4243\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2701 - accuracy: 0.4204\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2708 - accuracy: 0.4252\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2700 - accuracy: 0.4231\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2703 - accuracy: 0.4219\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2715 - accuracy: 0.4240\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2696 - accuracy: 0.4237\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2700 - accuracy: 0.4198\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2708 - accuracy: 0.4233\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2680 - accuracy: 0.4219\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2692 - accuracy: 0.4253\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2685 - accuracy: 0.4217\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2678 - accuracy: 0.4276\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2681 - accuracy: 0.4254\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2697 - accuracy: 0.4223\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2667 - accuracy: 0.4279\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2688 - accuracy: 0.4229\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2664 - accuracy: 0.4229\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2657 - accuracy: 0.4223\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2646 - accuracy: 0.4217\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2646 - accuracy: 0.4254\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2665 - accuracy: 0.4280\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2655 - accuracy: 0.4251\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2654 - accuracy: 0.4254\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2634 - accuracy: 0.4265\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2636 - accuracy: 0.4278\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2647 - accuracy: 0.4258\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2644 - accuracy: 0.4239\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2640 - accuracy: 0.4244\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2647 - accuracy: 0.4262\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2639 - accuracy: 0.4293\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2627 - accuracy: 0.4312\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2633 - accuracy: 0.4250\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2626 - accuracy: 0.4348\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2615 - accuracy: 0.4262\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2618 - accuracy: 0.4267\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2612 - accuracy: 0.4280\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2650 - accuracy: 0.4265\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2636 - accuracy: 0.4295\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2643 - accuracy: 0.4265\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2636 - accuracy: 0.4257\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2642 - accuracy: 0.4311\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2629 - accuracy: 0.4271\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2608 - accuracy: 0.4324\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2612 - accuracy: 0.4256\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2606 - accuracy: 0.4273\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2589 - accuracy: 0.4290\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2625 - accuracy: 0.4338\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2614 - accuracy: 0.4279\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2613 - accuracy: 0.4302\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2628 - accuracy: 0.4263\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2612 - accuracy: 0.4345\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2605 - accuracy: 0.4300\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2584 - accuracy: 0.4305\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2600 - accuracy: 0.4285\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2592 - accuracy: 0.4329\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2611 - accuracy: 0.4275\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2604 - accuracy: 0.4314\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2600 - accuracy: 0.4295\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2597 - accuracy: 0.4274\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2581 - accuracy: 0.4316\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2604 - accuracy: 0.4280\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2587 - accuracy: 0.4309\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2582 - accuracy: 0.4296\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2590 - accuracy: 0.4324\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2596 - accuracy: 0.4310\n",
      "133/133 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4568 - accuracy: 0.2030\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4558 - accuracy: 0.2030\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4548 - accuracy: 0.2030\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4538 - accuracy: 0.2030\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4529 - accuracy: 0.2030\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4520 - accuracy: 0.2030\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4511 - accuracy: 0.2030\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4502 - accuracy: 0.2030\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4494 - accuracy: 0.2030\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4486 - accuracy: 0.2545\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4478 - accuracy: 0.3099\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4471 - accuracy: 0.3099\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4464 - accuracy: 0.3099\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4457 - accuracy: 0.3099\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4450 - accuracy: 0.3099\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4443 - accuracy: 0.3099\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4437 - accuracy: 0.3099\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4430 - accuracy: 0.3099\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4424 - accuracy: 0.3099\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4418 - accuracy: 0.3099\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4413 - accuracy: 0.3099\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4407 - accuracy: 0.3099\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4402 - accuracy: 0.3099\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4396 - accuracy: 0.3099\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4391 - accuracy: 0.3099\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4386 - accuracy: 0.3099\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4381 - accuracy: 0.3099\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4377 - accuracy: 0.3099\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4372 - accuracy: 0.3099\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4368 - accuracy: 0.3099\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4363 - accuracy: 0.3099\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4359 - accuracy: 0.3099\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4355 - accuracy: 0.3099\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4351 - accuracy: 0.3099\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4347 - accuracy: 0.3099\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4343 - accuracy: 0.3099\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4340 - accuracy: 0.3099\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4336 - accuracy: 0.3099\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4332 - accuracy: 0.3099\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4329 - accuracy: 0.3099\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4326 - accuracy: 0.3099\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4323 - accuracy: 0.3099\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4319 - accuracy: 0.3099\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4316 - accuracy: 0.3099\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4313 - accuracy: 0.3099\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4310 - accuracy: 0.3099\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4308 - accuracy: 0.3099\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4305 - accuracy: 0.3099\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4302 - accuracy: 0.3099\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4299 - accuracy: 0.3099\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4297 - accuracy: 0.3099\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4294 - accuracy: 0.3099\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4292 - accuracy: 0.3099\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4289 - accuracy: 0.3099\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4287 - accuracy: 0.3099\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4285 - accuracy: 0.3099\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4283 - accuracy: 0.3099\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4281 - accuracy: 0.3099\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.3099\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.3099\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4274 - accuracy: 0.3099\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.3099\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4270 - accuracy: 0.3099\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4269 - accuracy: 0.3099\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3099\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4265 - accuracy: 0.3099\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4263 - accuracy: 0.3099\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4262 - accuracy: 0.3099\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4260 - accuracy: 0.3099\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4258 - accuracy: 0.3099\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4257 - accuracy: 0.3099\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4255 - accuracy: 0.3099\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4254 - accuracy: 0.3099\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4252 - accuracy: 0.3099\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4251 - accuracy: 0.3099\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4249 - accuracy: 0.3099\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4248 - accuracy: 0.3099\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4247 - accuracy: 0.3099\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4245 - accuracy: 0.3099\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4244 - accuracy: 0.3099\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4243 - accuracy: 0.3099\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4242 - accuracy: 0.3099\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4240 - accuracy: 0.3099\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4239 - accuracy: 0.3099\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4238 - accuracy: 0.3099\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4237 - accuracy: 0.3099\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4236 - accuracy: 0.3099\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4235 - accuracy: 0.3099\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4234 - accuracy: 0.3099\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4233 - accuracy: 0.3099\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4232 - accuracy: 0.3099\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4231 - accuracy: 0.3099\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4230 - accuracy: 0.3099\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4229 - accuracy: 0.3099\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4228 - accuracy: 0.3099\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4227 - accuracy: 0.3099\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4226 - accuracy: 0.3099\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4225 - accuracy: 0.3099\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4225 - accuracy: 0.3099\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4224 - accuracy: 0.3099\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3303 - accuracy: 0.3830\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3211 - accuracy: 0.3880\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3153 - accuracy: 0.3934\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3124 - accuracy: 0.3948\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3111 - accuracy: 0.3932\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3110 - accuracy: 0.3980\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3111 - accuracy: 0.3969\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3105 - accuracy: 0.3971\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3079 - accuracy: 0.3975\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3086 - accuracy: 0.3992\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3064 - accuracy: 0.3977\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3080 - accuracy: 0.3968\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3054 - accuracy: 0.4015\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3052 - accuracy: 0.3995\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3063 - accuracy: 0.3953\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3063 - accuracy: 0.4005\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3068 - accuracy: 0.4030\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3063 - accuracy: 0.3949\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3046 - accuracy: 0.3967\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3042 - accuracy: 0.3998\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3043 - accuracy: 0.3984\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3038 - accuracy: 0.3997\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3043 - accuracy: 0.4007\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3030 - accuracy: 0.3981\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3017 - accuracy: 0.3972\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3052 - accuracy: 0.3988\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3026 - accuracy: 0.4011\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3036 - accuracy: 0.3995\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3035 - accuracy: 0.3976\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3021 - accuracy: 0.4027\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3028 - accuracy: 0.4014\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3014 - accuracy: 0.4008\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3028 - accuracy: 0.4008\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3014 - accuracy: 0.4021\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3021 - accuracy: 0.3994\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3031 - accuracy: 0.3988\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3017 - accuracy: 0.4043\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3007 - accuracy: 0.4007\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3008 - accuracy: 0.3968\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3020 - accuracy: 0.4039\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3028 - accuracy: 0.4036\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2997 - accuracy: 0.3988\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3009 - accuracy: 0.3995\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3003 - accuracy: 0.4032\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3020 - accuracy: 0.3991\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2998 - accuracy: 0.3975\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2988 - accuracy: 0.4006\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2989 - accuracy: 0.4016\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3004 - accuracy: 0.3970\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3011 - accuracy: 0.3975\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3010 - accuracy: 0.4014\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2995 - accuracy: 0.4001\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2997 - accuracy: 0.3995\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2989 - accuracy: 0.4005\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2988 - accuracy: 0.4028\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2994 - accuracy: 0.4008\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2995 - accuracy: 0.4004\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2978 - accuracy: 0.4059\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2994 - accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2992 - accuracy: 0.4025\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2979 - accuracy: 0.4002\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2991 - accuracy: 0.4033\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2991 - accuracy: 0.4036\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2997 - accuracy: 0.4010\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2985 - accuracy: 0.4017\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2974 - accuracy: 0.4014\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2976 - accuracy: 0.4046\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2990 - accuracy: 0.4004\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2972 - accuracy: 0.4028\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2981 - accuracy: 0.4013\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2971 - accuracy: 0.4042\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2975 - accuracy: 0.4023\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2996 - accuracy: 0.4005\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2973 - accuracy: 0.4031\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2982 - accuracy: 0.4021\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2983 - accuracy: 0.4046\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2991 - accuracy: 0.4010\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2985 - accuracy: 0.3978\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2982 - accuracy: 0.4025\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2970 - accuracy: 0.4038\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2991 - accuracy: 0.4049\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2978 - accuracy: 0.4004\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2972 - accuracy: 0.4032\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2959 - accuracy: 0.4029\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2988 - accuracy: 0.4024\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2965 - accuracy: 0.4059\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2962 - accuracy: 0.4055\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2970 - accuracy: 0.4002\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2991 - accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2978 - accuracy: 0.4036\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2969 - accuracy: 0.4040\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2960 - accuracy: 0.4005\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2992 - accuracy: 0.4014\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2977 - accuracy: 0.4044\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2959 - accuracy: 0.4017\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2947 - accuracy: 0.4020\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2973 - accuracy: 0.4043\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2981 - accuracy: 0.3982\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2961 - accuracy: 0.4023\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.2968 - accuracy: 0.4047\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4315 - accuracy: 0.3007\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4196 - accuracy: 0.3099\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3085\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3078\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3076\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3090\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3053\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3055\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3092\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3090\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3062\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3086\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3072\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3050\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3025\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3074\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3082\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3071\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3062\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3059\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3080\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3070\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3032\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3075\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3091\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3085\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3086\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3082\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3065\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3069\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3074\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3067\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3079\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3088\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3083\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3086\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3038\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3095\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3046\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3078\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3076\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3063\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3098\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3076\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3057\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3078\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3078\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3049\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3070\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3070\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3054\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3083\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3111\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3059\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3067\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3081\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3099\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3089\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3096\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3073\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3083\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3050\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3025\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4215 - accuracy: 0.3037\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3060\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3044\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3080\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3109\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.3106\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3099\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3070\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3112\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3075\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3082\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3067\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3026\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3046\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3103\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3066\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3098\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3050\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3053\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3123\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3106\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3045\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3047\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3085\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3090\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3089\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3051\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3049\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3052\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3091\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3134\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3070\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3057\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3084\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3065\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3055\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3066\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3070\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3077\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3052\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3055\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3060\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3076\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3030\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3077\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3045\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3114\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3056\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3039\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3065\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3047\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3088\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3046\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3010\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3113\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3045\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3098\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3062\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3085\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3073\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3101\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3057\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3092\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3043\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3073\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3105\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3099\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3060\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3051\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.3130\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.3086\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3072\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3047\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3048\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3035\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3032\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3121\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3006\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3063\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3077\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3049\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3114\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3072\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3039\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3050\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3072\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3052\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3107\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3094\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3053\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3081\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4194 - accuracy: 0.3086\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3092\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4191 - accuracy: 0.3073\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3111\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.3056\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4195 - accuracy: 0.3047\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4254 - accuracy: 0.3036\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4193 - accuracy: 0.3086\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4190 - accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4188 - accuracy: 0.3086\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4187 - accuracy: 0.3086\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3027\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3065\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3077\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3070\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3099\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3045\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3076\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3087\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3078\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3076\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3034\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3099\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3075\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3056\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3065\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3058\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3040\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3040\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3073\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3096\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3098\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3113\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3051\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3041\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3077\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3116\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3024\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3088\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3076\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3060\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3055\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3098\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3041\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3085\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3088\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3071\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3092\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3130\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3053\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3031\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3075\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3076\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3064\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3082\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3108\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3070\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3073\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3091\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3066\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3056\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3059\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3071\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3046\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3053\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3015\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3123\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3072\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3077\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3118\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3091\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3091\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3045\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3088\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3032\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3051\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3071\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3086\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3093\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3045\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3075\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3089\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3058\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4184 - accuracy: 0.3075\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3103\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3065\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3093\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3081\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3074\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3075\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3071\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3085\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3086\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3082\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3050\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3086\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3030\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3053\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3091\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3064\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.3105\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4186 - accuracy: 0.3062\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4222 - accuracy: 0.3263\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4113 - accuracy: 0.3351\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4097 - accuracy: 0.3371\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4092 - accuracy: 0.3356\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4089 - accuracy: 0.3351\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4086 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4084 - accuracy: 0.3350\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4082 - accuracy: 0.3354\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4081 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4079 - accuracy: 0.3347\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4078 - accuracy: 0.3353\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4077 - accuracy: 0.3363\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4076 - accuracy: 0.3337\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4075 - accuracy: 0.3359\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4073 - accuracy: 0.3335\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4073 - accuracy: 0.3355\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4072 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4071 - accuracy: 0.3360\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4069 - accuracy: 0.3376\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4069 - accuracy: 0.3370\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4068 - accuracy: 0.3359\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4068 - accuracy: 0.3361\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4067 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4064 - accuracy: 0.3358\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4065 - accuracy: 0.3356\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4064 - accuracy: 0.3351\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4063 - accuracy: 0.3356\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4062 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4061 - accuracy: 0.3348\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4060 - accuracy: 0.3353\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4060 - accuracy: 0.3353\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4059 - accuracy: 0.3364\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4058 - accuracy: 0.3366\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4057 - accuracy: 0.3367\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4056 - accuracy: 0.3363\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4055 - accuracy: 0.3367\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4055 - accuracy: 0.3372\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4053 - accuracy: 0.3367\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4052 - accuracy: 0.3360\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4052 - accuracy: 0.3364\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4051 - accuracy: 0.3376\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4050 - accuracy: 0.3379\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4048 - accuracy: 0.3366\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4050 - accuracy: 0.3366\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4047 - accuracy: 0.3372\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4046 - accuracy: 0.3369\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4046 - accuracy: 0.3386\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4045 - accuracy: 0.3371\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4045 - accuracy: 0.3369\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4044 - accuracy: 0.3372\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4043 - accuracy: 0.3369\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4042 - accuracy: 0.3386\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4042 - accuracy: 0.3370\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4041 - accuracy: 0.3376\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4040 - accuracy: 0.3386\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4039 - accuracy: 0.3383\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4038 - accuracy: 0.3372\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4038 - accuracy: 0.3379\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4037 - accuracy: 0.3383\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4036 - accuracy: 0.3383\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4035 - accuracy: 0.3377\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4034 - accuracy: 0.3376\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4034 - accuracy: 0.3371\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4034 - accuracy: 0.3384\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4032 - accuracy: 0.3368\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4032 - accuracy: 0.3386\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4031 - accuracy: 0.3392\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4030 - accuracy: 0.3382\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4030 - accuracy: 0.3375\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4029 - accuracy: 0.3378\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4028 - accuracy: 0.3378\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4028 - accuracy: 0.3399\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4026 - accuracy: 0.3376\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4026 - accuracy: 0.3387\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4025 - accuracy: 0.3392\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4025 - accuracy: 0.3387\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4025 - accuracy: 0.3380\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4023 - accuracy: 0.3396\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4023 - accuracy: 0.3386\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4022 - accuracy: 0.3392\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4022 - accuracy: 0.3389\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4021 - accuracy: 0.3398\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4020 - accuracy: 0.3392\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4019 - accuracy: 0.3389\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4019 - accuracy: 0.3386\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4017 - accuracy: 0.3389\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4018 - accuracy: 0.3394\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4017 - accuracy: 0.3400\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4017 - accuracy: 0.3393\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4015 - accuracy: 0.3389\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4015 - accuracy: 0.3395\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4015 - accuracy: 0.3383\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4014 - accuracy: 0.3389\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4013 - accuracy: 0.3387\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4013 - accuracy: 0.3392\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4011 - accuracy: 0.3389\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4011 - accuracy: 0.3387\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4011 - accuracy: 0.3389\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4009 - accuracy: 0.3395\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4009 - accuracy: 0.3387\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4105 - accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4048 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4046 - accuracy: 0.3349\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4043 - accuracy: 0.3342\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4040 - accuracy: 0.3348\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4039 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4037 - accuracy: 0.3353\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4035 - accuracy: 0.3348\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4034 - accuracy: 0.3361\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4031 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4030 - accuracy: 0.3377\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4028 - accuracy: 0.3366\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4027 - accuracy: 0.3374\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4025 - accuracy: 0.3367\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4023 - accuracy: 0.3366\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4020 - accuracy: 0.3368\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4020 - accuracy: 0.3385\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4018 - accuracy: 0.3376\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4016 - accuracy: 0.3382\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4015 - accuracy: 0.3376\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4013 - accuracy: 0.3359\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4012 - accuracy: 0.3374\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4010 - accuracy: 0.3374\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4009 - accuracy: 0.3388\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4008 - accuracy: 0.3378\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4006 - accuracy: 0.3388\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4005 - accuracy: 0.3369\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4003 - accuracy: 0.3394\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4002 - accuracy: 0.3392\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3999 - accuracy: 0.3389\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3999 - accuracy: 0.3377\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3997 - accuracy: 0.3388\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3996 - accuracy: 0.3399\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3996 - accuracy: 0.3394\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3994 - accuracy: 0.3387\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3992 - accuracy: 0.3395\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3991 - accuracy: 0.3402\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3991 - accuracy: 0.3400\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3988 - accuracy: 0.3405\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3987 - accuracy: 0.3400\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3986 - accuracy: 0.3392\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3983 - accuracy: 0.3387\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3984 - accuracy: 0.3382\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3983 - accuracy: 0.3386\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3981 - accuracy: 0.3400\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3980 - accuracy: 0.3389\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3978 - accuracy: 0.3386\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3977 - accuracy: 0.3410\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3975 - accuracy: 0.3400\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3974 - accuracy: 0.3403\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3974 - accuracy: 0.3408\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3972 - accuracy: 0.3399\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3972 - accuracy: 0.3405\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3971 - accuracy: 0.3397\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3969 - accuracy: 0.3412\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3967 - accuracy: 0.3403\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3966 - accuracy: 0.3409\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3965 - accuracy: 0.3397\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3964 - accuracy: 0.3415\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3964 - accuracy: 0.3396\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3962 - accuracy: 0.3389\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3961 - accuracy: 0.3408\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3960 - accuracy: 0.3423\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3959 - accuracy: 0.3406\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3958 - accuracy: 0.3401\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3956 - accuracy: 0.3416\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3956 - accuracy: 0.3409\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3954 - accuracy: 0.3416\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3953 - accuracy: 0.3409\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3953 - accuracy: 0.3423\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3951 - accuracy: 0.3398\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3951 - accuracy: 0.3412\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3949 - accuracy: 0.3412\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3949 - accuracy: 0.3421\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3948 - accuracy: 0.3422\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3946 - accuracy: 0.3417\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3945 - accuracy: 0.3416\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3944 - accuracy: 0.3413\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3943 - accuracy: 0.3431\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3942 - accuracy: 0.3422\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3941 - accuracy: 0.3423\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3941 - accuracy: 0.3415\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3940 - accuracy: 0.3413\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3938 - accuracy: 0.3433\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3938 - accuracy: 0.3426\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3936 - accuracy: 0.3429\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3935 - accuracy: 0.3423\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3934 - accuracy: 0.3433\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3934 - accuracy: 0.3432\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3932 - accuracy: 0.3430\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3931 - accuracy: 0.3439\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3930 - accuracy: 0.3431\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3930 - accuracy: 0.3436\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3929 - accuracy: 0.3422\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3928 - accuracy: 0.3426\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3927 - accuracy: 0.3423\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3926 - accuracy: 0.3426\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3925 - accuracy: 0.3429\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3925 - accuracy: 0.3428\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.3924 - accuracy: 0.3431\n",
      "133/133 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4417 - accuracy: 0.2844\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4369 - accuracy: 0.2916\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4352 - accuracy: 0.2939\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4339 - accuracy: 0.2949\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4330 - accuracy: 0.2952\n",
      "Epoch 6/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4323 - accuracy: 0.2962\n",
      "Epoch 7/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4318 - accuracy: 0.2971\n",
      "Epoch 8/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4313 - accuracy: 0.2970\n",
      "Epoch 9/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4311 - accuracy: 0.2961\n",
      "Epoch 10/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4309 - accuracy: 0.2989\n",
      "Epoch 11/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4306 - accuracy: 0.2970\n",
      "Epoch 12/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4305 - accuracy: 0.2978\n",
      "Epoch 13/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4304 - accuracy: 0.2996\n",
      "Epoch 14/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4302 - accuracy: 0.2990\n",
      "Epoch 15/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4301 - accuracy: 0.2985\n",
      "Epoch 16/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4301 - accuracy: 0.2984\n",
      "Epoch 17/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4299 - accuracy: 0.2999\n",
      "Epoch 18/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4299 - accuracy: 0.2984\n",
      "Epoch 19/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4297 - accuracy: 0.2981\n",
      "Epoch 20/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4297 - accuracy: 0.3000\n",
      "Epoch 21/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4296 - accuracy: 0.2992\n",
      "Epoch 22/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4296 - accuracy: 0.2978\n",
      "Epoch 23/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4295 - accuracy: 0.2975\n",
      "Epoch 24/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4295 - accuracy: 0.2991\n",
      "Epoch 25/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4294 - accuracy: 0.3004\n",
      "Epoch 26/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4293 - accuracy: 0.3013\n",
      "Epoch 27/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4293 - accuracy: 0.2988\n",
      "Epoch 28/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4292 - accuracy: 0.2994\n",
      "Epoch 29/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4292 - accuracy: 0.3002\n",
      "Epoch 30/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4291 - accuracy: 0.2997\n",
      "Epoch 31/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4290 - accuracy: 0.2985\n",
      "Epoch 32/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4290 - accuracy: 0.2999\n",
      "Epoch 33/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4290 - accuracy: 0.3007\n",
      "Epoch 34/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4289 - accuracy: 0.2993\n",
      "Epoch 35/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4289 - accuracy: 0.2988\n",
      "Epoch 36/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4288 - accuracy: 0.2996\n",
      "Epoch 37/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4288 - accuracy: 0.2986\n",
      "Epoch 38/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4287 - accuracy: 0.3002\n",
      "Epoch 39/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4287 - accuracy: 0.3004\n",
      "Epoch 40/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4285 - accuracy: 0.3007\n",
      "Epoch 41/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4285 - accuracy: 0.3008\n",
      "Epoch 42/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4286 - accuracy: 0.3001\n",
      "Epoch 43/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4285 - accuracy: 0.3004\n",
      "Epoch 44/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4285 - accuracy: 0.3004\n",
      "Epoch 45/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4284 - accuracy: 0.2994\n",
      "Epoch 46/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4283 - accuracy: 0.3003\n",
      "Epoch 47/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4284 - accuracy: 0.3003\n",
      "Epoch 48/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4283 - accuracy: 0.2997\n",
      "Epoch 49/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4283 - accuracy: 0.3012\n",
      "Epoch 50/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4282 - accuracy: 0.3007\n",
      "Epoch 51/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4282 - accuracy: 0.3007\n",
      "Epoch 52/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4280 - accuracy: 0.3003\n",
      "Epoch 53/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4281 - accuracy: 0.3000\n",
      "Epoch 54/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4280 - accuracy: 0.3005\n",
      "Epoch 55/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4280 - accuracy: 0.3003\n",
      "Epoch 56/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4279 - accuracy: 0.3006\n",
      "Epoch 57/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4279 - accuracy: 0.2990\n",
      "Epoch 58/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.2999\n",
      "Epoch 59/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.2998\n",
      "Epoch 60/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4279 - accuracy: 0.3013\n",
      "Epoch 61/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4277 - accuracy: 0.3005\n",
      "Epoch 62/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.3002\n",
      "Epoch 63/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4277 - accuracy: 0.3015\n",
      "Epoch 64/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.2999\n",
      "Epoch 65/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.3005\n",
      "Epoch 66/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.3006\n",
      "Epoch 67/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.3006\n",
      "Epoch 68/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4274 - accuracy: 0.2994\n",
      "Epoch 69/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4275 - accuracy: 0.3011\n",
      "Epoch 70/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4274 - accuracy: 0.3005\n",
      "Epoch 71/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4274 - accuracy: 0.2994\n",
      "Epoch 72/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4273 - accuracy: 0.3003\n",
      "Epoch 73/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.2997\n",
      "Epoch 74/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.3007\n",
      "Epoch 75/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.3007\n",
      "Epoch 76/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.3007\n",
      "Epoch 77/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4271 - accuracy: 0.3008\n",
      "Epoch 78/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4271 - accuracy: 0.3010\n",
      "Epoch 79/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4271 - accuracy: 0.3009\n",
      "Epoch 80/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4270 - accuracy: 0.3010\n",
      "Epoch 81/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4271 - accuracy: 0.3004\n",
      "Epoch 82/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4269 - accuracy: 0.2998\n",
      "Epoch 83/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4269 - accuracy: 0.3009\n",
      "Epoch 84/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4268 - accuracy: 0.2996\n",
      "Epoch 85/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4270 - accuracy: 0.3003\n",
      "Epoch 86/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4269 - accuracy: 0.3002\n",
      "Epoch 87/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3008\n",
      "Epoch 88/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4268 - accuracy: 0.3005\n",
      "Epoch 89/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3008\n",
      "Epoch 90/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3007\n",
      "Epoch 92/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.3007\n",
      "Epoch 93/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4266 - accuracy: 0.3003\n",
      "Epoch 94/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4265 - accuracy: 0.2998\n",
      "Epoch 95/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4266 - accuracy: 0.3000\n",
      "Epoch 96/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4265 - accuracy: 0.3010\n",
      "Epoch 97/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4265 - accuracy: 0.3012\n",
      "Epoch 98/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4264 - accuracy: 0.3010\n",
      "Epoch 99/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4263 - accuracy: 0.3004\n",
      "Epoch 100/100\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 1.4263 - accuracy: 0.3008\n",
      "133/133 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABICElEQVR4nO3dd3hT5cPG8TstbQqdUEaZZe8Csguyl6jIEJGlgOJiyBBkKEJRKSpbZCgIiCAqCA4URBAQRWTPgmxQdoGySluavH/4Wn+xgC00PQ/t93NdvS7znCfn3GlMenPyJLE5nU6nAAAAAAN5WB0AAAAAuBXKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqANzE/v371bRpUwUGBspms2nJkiVpuv8jR47IZrNp9uzZabrfe1n9+vVVv359q2MAMAxlFYCxDh48qOeee05FixaVj4+PAgICVLt2bU2cOFGxsbFuPXaXLl20c+dOvfnmm5o7d66qVq3q1uOlp65du8pmsykgIOCmv8f9+/fLZrPJZrNpzJgxqd7/iRMnNGLECG3bti0N0gLI7LJYHQAAbmbp0qV67LHHZLfb9eSTT6p8+fKKj4/XunXrNHDgQO3evVvvv/++W44dGxur9evX65VXXlGvXr3ccozQ0FDFxsbKy8vLLfv/L1myZNG1a9f09ddfq127di7b5s2bJx8fH12/fv2O9n3ixAlFRESocOHCqlSpUoqv9/3339/R8QBkbJRVAMY5fPiw2rdvr9DQUK1atUp58+ZN2tazZ08dOHBAS5cuddvxz549K0kKCgpy2zFsNpt8fHzctv//YrfbVbt2bX3yySfJyur8+fP10EMPadGiRemS5dq1a8qWLZu8vb3T5XgA7i0sAwBgnLfffltXrlzRzJkzXYrq34oXL64+ffokXb5x44Zef/11FStWTHa7XYULF9bQoUMVFxfncr3ChQvr4Ycf1rp161S9enX5+PioaNGi+uijj5LmjBgxQqGhoZKkgQMHymazqXDhwpL+evn87//+XyNGjJDNZnMZW7Fihe6//34FBQXJz89PpUqV0tChQ5O232rN6qpVq1SnTh35+voqKChILVu2VFRU1E2Pd+DAAXXt2lVBQUEKDAxUt27ddO3atVv/Yv+lY8eO+u6773Tx4sWksY0bN2r//v3q2LFjsvnnz5/XgAEDFBYWJj8/PwUEBKh58+bavn170pzVq1erWrVqkqRu3bolLSf4+3bWr19f5cuX1+bNm1W3bl1ly5Yt6ffy7zWrXbp0kY+PT7Lb36xZM2XPnl0nTpxI8W0FcO+irAIwztdff62iRYuqVq1aKZrfvXt3vfbaa6pcubLGjx+vevXqKTIyUu3bt08298CBA2rbtq2aNGmisWPHKnv27Oratat2794tSWrTpo3Gjx8vSerQoYPmzp2rCRMmpCr/7t279fDDDysuLk4jR47U2LFj9cgjj+jnn3++7fV++OEHNWvWTGfOnNGIESPUv39//fLLL6pdu7aOHDmSbH67du10+fJlRUZGql27dpo9e7YiIiJSnLNNmzay2Wz64osvksbmz5+v0qVLq3LlysnmHzp0SEuWLNHDDz+scePGaeDAgdq5c6fq1auXVBzLlCmjkSNHSpKeffZZzZ07V3PnzlXdunWT9hMdHa3mzZurUqVKmjBhgho0aHDTfBMnTlSuXLnUpUsXJSYmSpKmT5+u77//Xu+++67y5cuX4tsK4B7mBACDxMTEOCU5W7ZsmaL527Ztc0pydu/e3WV8wIABTknOVatWJY2FhoY6JTnXrl2bNHbmzBmn3W53vvTSS0ljhw8fdkpyvvPOOy777NKlizM0NDRZhuHDhzv/9+l0/PjxTknOs2fP3jL338eYNWtW0lilSpWcuXPndkZHRyeNbd++3enh4eF88sknkx3vqaeectln69atncHBwbc85v/eDl9fX6fT6XS2bdvW2ahRI6fT6XQmJiY6Q0JCnBERETf9HVy/ft2ZmJiY7HbY7XbnyJEjk8Y2btyY7Lb9rV69ek5JzmnTpt10W7169VzGli9f7pTkfOONN5yHDh1y+vn5OVu1avWftxFAxsGZVQBGuXTpkiTJ398/RfO//fZbSVL//v1dxl966SVJSra2tWzZsqpTp07S5Vy5cqlUqVI6dOjQHWf+t7/Xun755ZdyOBwpus7Jkye1bds2de3aVTly5Egar1Chgpo0aZJ0O//X888/73K5Tp06io6OTvodpkTHjh21evVqnTp1SqtWrdKpU6duugRA+mudq4fHX382EhMTFR0dnbTEYcuWLSk+pt1uV7du3VI0t2nTpnruuec0cuRItWnTRj4+Ppo+fXqKjwXg3kdZBWCUgIAASdLly5dTNP/o0aPy8PBQ8eLFXcZDQkIUFBSko0ePuowXKlQo2T6yZ8+uCxcu3GHi5B5//HHVrl1b3bt3V548edS+fXt99tlnty2uf+csVapUsm1lypTRuXPndPXqVZfxf9+W7NmzS1KqbsuDDz4of39/ffrpp5o3b56qVauW7Hf5N4fDofHjx6tEiRKy2+3KmTOncuXKpR07digmJibFx8yfP3+q3kw1ZswY5ciRQ9u2bdOkSZOUO3fuFF8XwL2PsgrAKAEBAcqXL5927dqVquv9+w1Ot+Lp6XnTcafTecfH+Hs95d+yZs2qtWvX6ocfftATTzyhHTt26PHHH1eTJk2Szb0bd3Nb/ma329WmTRvNmTNHixcvvuVZVUkaNWqU+vfvr7p16+rjjz/W8uXLtWLFCpUrVy7FZ5Clv34/qbF161adOXNGkrRz585UXRfAvY+yCsA4Dz/8sA4ePKj169f/59zQ0FA5HA7t37/fZfz06dO6ePFi0jv700L27Nld3jn/t3+fvZUkDw8PNWrUSOPGjdOePXv05ptvatWqVfrxxx9vuu+/c+7bty/Ztr179ypnzpzy9fW9uxtwCx07dtTWrVt1+fLlm74p7W8LFy5UgwYNNHPmTLVv315NmzZV48aNk/1OUvoPh5S4evWqunXrprJly+rZZ5/V22+/rY0bN6bZ/gGYj7IKwDgvv/yyfH191b17d50+fTrZ9oMHD2rixImS/noZW1Kyd+yPGzdOkvTQQw+lWa5ixYopJiZGO3bsSBo7efKkFi9e7DLv/Pnzya7794fj//vjtP6WN29eVapUSXPmzHEpf7t27dL333+fdDvdoUGDBnr99dc1efJkhYSE3HKep6dnsrO2n3/+uf7880+Xsb9L9c2KfWoNGjRIx44d05w5czRu3DgVLlxYXbp0ueXvEUDGw5cCADBOsWLFNH/+fD3++OMqU6aMyzdY/fLLL/r888/VtWtXSVLFihXVpUsXvf/++7p48aLq1aun3377TXPmzFGrVq1u+bFId6J9+/YaNGiQWrdurRdffFHXrl3T1KlTVbJkSZc3GI0cOVJr167VQw89pNDQUJ05c0ZTpkxRgQIFdP/9999y/++8846aN2+u8PBwPf3004qNjdW7776rwMBAjRgxIs1ux795eHjo1Vdf/c95Dz/8sEaOHKlu3bqpVq1a2rlzp+bNm6eiRYu6zCtWrJiCgoI0bdo0+fv7y9fXVzVq1FCRIkVSlWvVqlWaMmWKhg8fnvRRWrNmzVL9+vU1bNgwvf3226naH4B7E2dWARjpkUce0Y4dO9S2bVt9+eWX6tmzpwYPHqwjR45o7NixmjRpUtLcGTNmKCIiQhs3blTfvn21atUqDRkyRAsWLEjTTMHBwVq8eLGyZcuml19+WXPmzFFkZKRatGiRLHuhQoX04YcfqmfPnnrvvfdUt25drVq1SoGBgbfcf+PGjbVs2TIFBwfrtdde05gxY1SzZk39/PPPqS567jB06FC99NJLWr58ufr06aMtW7Zo6dKlKliwoMs8Ly8vzZkzR56ennr++efVoUMHrVmzJlXHunz5sp566indd999euWVV5LG69Spoz59+mjs2LH69ddf0+R2ATCbzZmalfgAAABAOuLMKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjZchvsMp6Xy+rIyAdHVo9zuoISEdxCQ6rIyAdBfl6WR0B6cjHy9PqCEhHPilsoZxZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWTVc7crFtHDCczr0/ZuK3TpZLepXuOXcSa+0V+zWyerVsb7L+N6lEYrdOtnlZ0C3Jm5OjrSwfcsmDenfS48+2FD1q4fpp9UrXbbPen+KnnishR6oW10PN6ql/j27a8+uHRalxd3auW2zXnu5tzo80ljNalfUL2tXuWyPvXZNk8eOUqdWTdSiQXU906m1vln8mUVp4Q5nTp/W8KEvq0m9cNWtcZ86tm2pqN27rI4FN1owf56aN2moaveFqVP7x7RzB8/h/5bF6gC4Pd+sdu38/U999OV6fTru2VvOe6RBBVUPK6wTZy7edHvElG8064ufky5fvhqX1lHhBtevx6pYiZJ6sEVrDRvUN9n2goVC1WfgUOXLX0Bx1+P0+SdzNbD3c5r3xVIFZc+R/oFxV67Hxqpo8VJq9lArjRzaP9n26e+O0bbNv+nl10YpT9582vLber07dpSCc+ZWeJ366R8YaerSpRg927WTKlerrgmTpyt7jhw6dvSo/AMCrI4GN1n23bca83akXh0eobCwipo3d45eeO5pffnNMgUHB1sdzxiUVcN9//Meff/zntvOyZcrUOMGPaYWPd7T4ndfuOmcK1ev63T0ZXdEhBvVqFVHNWrVueX2xg885HK5Z9+B+varL3Rw/++qUr2mu+MhjVULv1/Vwu+/5fY9O7epSfMWqli5miTpwZZttfTLhdoXtYuymgHMnTVTuUNC9NrIUUlj+fIXsDAR3G3unFlq07adWrV+VJL06vAIrV27Wku+WKSnn7n1CarMxtJlAOfOndPbb7+t1q1bKzw8XOHh4WrdurXeeecdnT171spo9wybzaaZbzyp8XNWKurQqVvOe6lbU/3x41ta/8kg9XuykTw9WQGS0SQkJOjrJQvl6+evYiVLWR0HblA2rJJ+XbdG586eltPp1LbNv+nPY0dVpXq41dGQBtauWaUyZctryIC+eqDB/Xri8TZasuhzq2PBTRLi4xW1Z7dqhtdKGvPw8FDNmrW0Y/tWC5OZx7Izqxs3blSzZs2ULVs2NW7cWCVLlpQknT59WpMmTdLo0aO1fPlyVa1a9bb7iYuLU1yc60vaTkeibB6ebstukpe6NdGNRIfe+2T1LedM+WSNtkYd14VLV1WzYlGN7P2IQnIFatDYL9IvKNzml5/WaOSrAxV3/bqCc+bS2MnvKygou9Wx4AY9+g3WxLdGqlOrpvL0zCIPD5v6DBqusEpVrI6GNHDijz/0xecL1KFzF3Xt/qz27NqlcW+PkpeXlx56pJXV8ZDGLly8oMTExGQv9wcHB+vw4UMWpTKTZWW1d+/eeuyxxzRt2jTZbDaXbU6nU88//7x69+6t9evX33Y/kZGRioiIcBnzzFNNXnmrp3lm09xXpqB6dqivWh3fuu28SR//8yaNXftPKD7hhia/0kHDJn2l+IQb7o4JN7uvajXN+HihYi5e0NIlizRiyABNnTVP2XOw3imj+XLhJ9q7e4ci3pqo3CH5tHPbZr03dpSCc+ZS5Wos+7jXORwOlSlbXj1e7CdJKlW6rA4d3K8vFn5KWUWmZtlrwdu3b1e/fv2SFVXpr5e2+/Xrp23btv3nfoYMGaKYmBiXnyx5MsdZhtr3FVPuHH76/duRurxxoi5vnKjQfMEa3b+N9i6NuOX1Nu48Ii8vT4Xm4w04GUHWrNlUoGAhlQurqJeHjZRnFk99+9Viq2MhjcXFXdfs6ZP07IsDVPP++ipavKRatu2geo2aaeEnc6yOhzSQM1cuFSlWzGWscJFiOn3ypEWJ4E7Zg7LL09NT0dHRLuPR0dHKmTOnRanMZNmZ1ZCQEP32228qXbr0Tbf/9ttvypMnz3/ux263y263u4xlliUA85du1KoN+1zGvp7SU/OX/qaPvvz1lterWKqAEhMdOnueN1xlRE6HQ/Hx8VbHQBq7ceOGbty4IQ+b6zkGD08POR0Oi1IhLVWoWFlHjxx2GTt29IhC8uazKBHcycvbW2XKltOGX9erYaPGkv46u75hw3q179DZ4nRmsaysDhgwQM8++6w2b96sRo0aJRXT06dPa+XKlfrggw80ZswYq+IZwzert4oVzJV0uXD+YFUomV8XLl3T8VMXdD7mqsv8hBuJOn3ukvYfPSNJqlGhiKqVD9WaTft1+ep11axQRG8NeFSffLtRFy/HputtQepdu3ZNf/5xLOnyqRN/av/vexUQEKiAwEB9POsD1apTX8E5cynm4gUtWbhAZ8+eUf1GTS1MjTsVe+2aTvzr/j74+175BwQqd0heVbivqj54b5y87XblCcmrHVs364fvvtGzLw6wMDXSSofOT6p7106aPWO6GjV9QHt27dSSRZ9ryLARVkeDmzzRpZuGDR2kcuXKq3xYBX08d45iY2PVqnUbq6MZxeZ0Op1WHfzTTz/V+PHjtXnzZiUmJkqSPD09VaVKFfXv31/t2rW7o/1mva9XWsa0VJ0qJfT9jD7Jxud+9aueHf5xsvG9SyM0ed6Pmjx/tSSpUukCmjjkcZUskkd2ryw6ciJa85du1KS5qzLMetVDq8dZHcFttm7eqH4vPJVsvNlDj6j/4Nf0xrBBitq9UzEXLyggMEily5bTE089p9Jly1uQNn3EJWTcs4jbt2zUy727Jxtv0vwRDXj1dZ2PPqcPp03Ult/W6/KlS8odklcPtnxUbR5/4qZLqjKCIF8vqyOkq3VrV2vKpPE6fuyo8uUvoA6du6jVo49ZHSvd+HhljldG/9cn8z7WnFkzde7cWZUqXUaDhr6qChUqWh0rXfik8JSppWX1bwkJCTp37pwkKWfOnPLyursnp4xUVvHfMnJZRXIZuawiucxWVjO7zFhWM7OUllUjvhTAy8tLefPmtToGAAAADMMnwwMAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADCWzel0Oq0Okdb+vBhvdQSkox6f77A6AtLRhx0rWR0B6eh6gsPqCEhHwX7eVkdAOvLJkrJ5nFkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZvcds37pJQ1/qpcceaqiGNcK0bs3KW84dP3qkGtYI08JP5qZjQqQVD5vUsUo+vd8+TJ91q6xpj5dXu/vyusx5sV5hfflMVZef4Q+UsCgx0lpiYqLenzJJjz7cVPXDK6vtIw9o1gdT5XQ6rY6GNMDzOSRpwfx5at6koardF6ZO7R/Tzh07rI5knCxWB0DqXI+NVbESJdW8RWsNH9T3lvN+Wr1Se3btUHCu3OkXDmmqTcUQNS+bSxNWH9HxC7EqnstXL9YtrGvxifpm95mkeZuPx2jSmsNJlxMSKTIZxcezZ2rxwk/1asQoFS1WXFF7dmnUiFfl6+evdh06Wx0Pd4nncyz77luNeTtSrw6PUFhYRc2bO0cvPPe0vvxmmYKDg62OZwzK6j2mRq06qlGrzm3nnD1zWu+OGaW3Jk3X0P490ykZ0lrpPH7acPSiNh+PkSSduRKvOsVyqEQuX5d5CYkOXYy9YUVEuNnO7dtUp15D1a5TT5KUN19+/bDsW+3ZtdPiZEgLPJ9j7pxZatO2nVq1flSS9OrwCK1du1pLvlikp5951uJ05mAZQAbjcDgUOWKoHu/cTUWKFrc6Du7C3tNXVCFfgPIF2iVJhXNkVdk8ftry/+X1b+Xz+mtO54qa8lh5PV+7kPztnlbEhRuEVaykTb/9qmNHj0iS9v++V9u3bVV47dsXHGQMPJ9nbAnx8Yras1s1w2sljXl4eKhmzVrasX2rhcnMY/SZ1ePHj2v48OH68MMPbzknLi5OcXFx/xqzyW63uzuekRZ89KE8PT3V5vFOVkfBXVq07ZSyeXnqvcfKy+F0ysNm08cb/9Sag+eT5mw9HqNfD1/Q6cvxCgmw64lq+fXaAyU16KsoOVgNcM97olt3Xb16RR3aPCwPT085EhP1XM8+avbgw1ZHQzrg+Txju3DxghITE5O93B8cHKzDhw9ZlMpMRp9ZPX/+vObMmXPbOZGRkQoMDHT5mTz+7XRKaJbfo3Zr0acfa9Brb8hms1kdB3fp/qLZVa94sMatOqT+X0Rp4urDalUhRA1K/PPE9tOhC/rtWIyOXojVhqMX9fry/SqZ21fl8/pbmBxpZeWKZfr+u6UaMeptzZ73uV6NGKX5c2fp26+XWB0NbsbzOfAPS8+sfvXVV7fdfujQf//LYsiQIerfv7/L2LnYzPnA3rFtiy5eOK/2LZsmjTkSEzVt0hgt+vRjfbJkuYXpkFpdaxTUou0n9dOhC5KkoxdilcvfrraVQvTj/uibXuf05XjFxCYob4BdO05cTs+4cIP3JozVE12fVpNmD0qSipUoqVOnTuijWTP0YItW1oaDW/F8nvFlD8ouT09PRUe7Pp9HR0crZ86cFqUyk6VltVWrVrLZbLf9GJb/+hel3W5P9pL/ZUd8muS71zR5sIWqVK/pMvZyn+fVpPnDeuDhVtaEwh3zzuKR7KV8h8N528dEsK+X/H2y6MK1BDenQ3q4fj1WNg/XF8A8PTzldDgsSoT0wvN5xufl7a0yZctpw6/r1bBRY0l/rVPesGG92vNpHy4sLat58+bVlClT1LJly5tu37Ztm6pUqZLOqcwWe+2a/vzjWNLlkyf+1IHf98o/IFB5QvIqMDDIZX6WLFmUI0dOFQotks5Jcbc2Hruoxyrl1dkr8Tp+IVZFc2ZTy7A8+uH3c5Iknyweal85n345ckEXryUoJMCuLtUL6OSlOG3545LF6ZEW7q9bX3Nmvq88IXlVtFhx/b43Sgs+nqOHWra2OhrSAM/neKJLNw0bOkjlypVX+bAK+njuHMXGxqpV6zZWRzOKpWW1SpUq2rx58y3L6n+ddc2M9kXtVv8eTyVdnjrhHUlSs4ce0aDX3rQqFtzgg1+OqWOV/Hq+diEFZvXS+WvxWr73rD7dclKS5HA6VTg4qxqUDJavt6fOX0vQtj8uad7mP3WDd1dlCP1efkUfTJmkMZGv68KF88qZK7daPvqYnnr2BaujIQ3wfI4Hmj+oC+fPa8rkSTp37qxKlS6jKdNnKJhlAC5sTgvb4E8//aSrV6/qgQceuOn2q1evatOmTapXr16q9vvnxcy5DCCz6vE53/aRmXzYsZLVEZCOriew5CEzCfbztjoC0pFPCk+ZWnpmtU6d239WoK+vb6qLKgAAADIOoz+6CgAAAJkbZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxslgdwB3eWXPI6ghIR+NalrM6AtLRTwfPWR0B6ahygexWRwBgMc6sAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGuqOy+tNPP6lz584KDw/Xn3/+KUmaO3eu1q1bl6bhAAAAkLmluqwuWrRIzZo1U9asWbV161bFxcVJkmJiYjRq1Kg0DwgAAIDMK9Vl9Y033tC0adP0wQcfyMvLK2m8du3a2rJlS5qGAwAAQOaW6rK6b98+1a1bN9l4YGCgLl68mBaZAAAAAEl3UFZDQkJ04MCBZOPr1q1T0aJF0yQUAAAAIN1BWX3mmWfUp08fbdiwQTabTSdOnNC8efM0YMAAvfDCC+7ICAAAgEwqS2qvMHjwYDkcDjVq1EjXrl1T3bp1ZbfbNWDAAPXu3dsdGQEAAJBJ2ZxOp/NOrhgfH68DBw7oypUrKlu2rPz8/NI62x3r++VeqyO4zWtNiilHNq9k4z8dvqBFO04rPDRQVQoEqkCgXT5enhqy9HfF3nBYkDT99A4PtTqC23w6d6Z+WbtSfxw9Im+7XWXKV9RTL/RVgUKFk+bEx8Xpg/fGau3K5UpIiFfl6rXUs/9QZc8RbF1wN9p5KsbqCOnix8XztGz++6r9YFs90q23zp85qbd6tr/p3E79R6hCeIP0DZhOKhfIbnUEt9mxdZM+nzdbv++L0vlzZzVi9ATVrtfQZc7RI4c0473x2rF1sxyJN1SoSDENHzVOuUPyWpTavXIH2K2OkO4WzJ+nObNm6ty5sypZqrQGDx2msAoVrI6VLnxSeMo01WdW/+bt7a2yZcve6dVxh8auOSIP2z+X8wbY1aNWIW3/87IkydvTQ1FnrijqzBW1KJvbopRIK7u2bdbDrR9XyTLllJiYqDnT39Ur/V/Q9LlfyCdrVknS+++O0cb1P2nIyHfk6+enqeNH641X+mvs1DkWp8edOn4gShtWfKW8ocWSxoKCc+vV979wmbfhh6+15qsFKlWpRnpHRBq4fj1WRUuUUrOHWytiSL9k20/8cVz9nuui5i1aq0v3Hsrm66cjhw/Iy9vbgrRwh2Xffasxb0fq1eERCgurqHlz5+iF557Wl98sU3BwxjzhcCdSXVYbNGggm812y+2rVq26q0C4vavxiS6XG+fx09kr8ToQfU2StObQBUlS8eBs6Z4Nae/1sVNcLvcfOlIdHmmo/fv2KKxSFV29clnfL12sl1+LVKUq1SVJ/YZE6LnOrbV39w6VLpc5/nWekcTFXtOCSW/o0ecHatWiuUnjHp6e8s/u+sdr928/qUJ4A9mz8ni/F1UPr6Pq4XVuuX3W9HdVvVYdPdOrf9JYvgIF0yMa0sncObPUpm07tWr9qCTp1eERWrt2tZZ8sUhPP/OsxenMkeo3WFWqVEkVK1ZM+ilbtqzi4+O1ZcsWhYWFuSMjbsHTJlUpEKANxzLHy6KQrl69IknyDwiUJO3fF6UbN26oUtV/zqwVDC2iXHnyKmrXdksy4u4smTlBpSuHq0SFqred98fBfTpx5ICqNXoonZIhPTkcDm34Za0KFAzV4L7P67EH66n30x318xpOCGUUCfHxitqzWzXDayWNeXh4qGbNWtqxfauFycyT6jOr48ePv+n4iBEjdOXKlbsOhJQLy+uvrF6e+u04ZTUzcDgcmj7pHZUNq6TCRYtLki6cP6csXl7y8w9wmZs9Rw5dOB9tRUzchW0/r9SJQ7+r1+jp/zl346qlyp0/VIVLlU+HZEhvFy+cV+y1a/p07kx1fba3uvfoq02//qyIIf30zuSZqlj59v+YgfkuXLygxMTEZC/3BwcH6/DhQxalMlOqz6zeSufOnfXhhx+m+nqxsbFat26d9uzZk2zb9evX9dFHH932+nFxcbp06ZLLz42E+FTnuBfVDA1U1JmrunT9htVRkA6mjIvU0cMHNHjEW1ZHgRtcPHdGX896V+37DJOX9+3fZJIQF6dt61ZyVjUDczj+emNseJ0GerTDEypesrTaP/m0atSuq2+WfGZxOiB9pVlZXb9+vXx8fFJ1nd9//11lypRR3bp1FRYWpnr16unkyZNJ22NiYtStW7fb7iMyMlKBgYEuP5sWvn9Ht+Fekj1rFpXM5atfj160OgrSwZTxkfpt/VqNnjhDOXPnSRrPniOnbiQk6MrlSy7zL5w/n2E/DSCj+vPQPl2JuaBJLz+jIY831JDHG+rQnm365btFGvJ4QzkS/1mvvvPX1UqIu67KdZtZmBjuFBiUXZ6eWRRapJjLeKHCRXXm1CmLUiEtZQ/KLk9PT0VHu74KFh0drZw5c1qUykypXgbQpk0bl8tOp1MnT57Upk2bNGzYsFTta9CgQSpfvrw2bdqkixcvqm/fvqpdu7ZWr16tQoUKpWgfQ4YMUf/+/V3Ghn5/JFU57kU1CgXpclyi9pxm6UVG5nQ6NXXCaK1fu0qjJ81QSL78LttLlCqjLFmyaNvm33R//caSpD+OHdHZ0ydVpnxFKyLjDhUPq6J+Y2e5jH0+ZbRy5Suk+q06ysPTM2l846pvVaZqbfkFBqVzSqQXLy8vlSpTTsePHXEZ//PYUeXJoB9bldl4eXurTNly2vDrejVs9Nfzt8Ph0IYN69W+Q2eL05kl1WU1MDDQ5bKHh4dKlSqlkSNHqmnTpqna1y+//KIffvhBOXPmVM6cOfX111+rR48eqlOnjn788Uf5+vr+5z7sdrvsdteXzLJ4ZeyP9bBJql4oUBuPx8jxr0/J9bd7KsCeRTl9//os1rwBdsXdcOhCbIKuJWTsz1vNiKaMG6XVP3yn10ZNUNZsvjoffU6S5OvnJ7vdR75+/mr6UGt9MHms/AMClc3XV9MmjFaZ8hX4JIB7jD1rNoUUcv3Kam97VmXzD3QZP3fyDx2O2q5uQ1gOcq+LvXZNf/5xLOnyqRN/6sDvexUQEKjcIXn1WKeuenPYQFWoVFkVK1fXxl9/1vqf12jsezMtTI209ESXbho2dJDKlSuv8mEV9PHcOYqNjVWr1m3++8qZSKrKamJiorp166awsDBlz373H9QcGxurLFn+iWCz2TR16lT16tVL9erV0/z58+/6GBlRyVzZlCOblzbcZAlA7cLZ9UDpf14+eLHOXx+YP3/LSd6IdQ9auuRzSdKgF7u7jPcbEqEmD7aUJD3be4BsHja9+epLSkiIV5XqtdSj/9B0z4r0senHbxWQI5dKVKxmdRTcpd/37taAnk8nXZ426R1JUpMHH9HLw97Q/fUbqc/Lw/TJRzP13ri3VCC0sIaPGqfyFStbFRlp7IHmD+rC+fOaMnmSzp07q1Kly2jK9BkKZhmAi1R/g5WPj4+ioqJUpEiRuz549erV1bt3bz3xxBPJtvXq1Uvz5s3TpUuXlJiYeJNr31pG/gYrJJeRv8EKyWWWb7DCXzLyN1ghucz4DVaZWUq/wSrVb7AqX768Dh1Km49UaN26tT755JObbps8ebI6dOigO/w2WAAAAGQAqT6zumzZMg0ZMkSvv/66qlSpkmxdaUBAwC2umX44s5q5cGY1c+HMaubCmdXMhTOrmUtKz6ymeM3qyJEj9dJLL+nBBx+UJD3yyCMuX7vqdDpls9lS/ZI9AAAAcCspLqsRERF6/vnn9eOPP7ozDwAAAJAkxWX179UC9erVc1sYAAAA4H+l6g1W//uyPwAAAOBuqfqc1ZIlS/5nYT1//vxdBQIAAAD+lqqyGhERkewbrAAAAAB3SVVZbd++vXLnzu2uLAAAAICLFK9ZZb0qAAAA0luKyyrfJAUAAID0luJlAA6Hw505AAAAgGRS9dFVAAAAQHqirAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCyb0+l0Wh0irf24L9rqCEhHwdnsVkdAOrrhcFgdAeloyd7TVkdAOhraqITVEZCOfLKkbB5nVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjZbE6AO7csoUfaclH09SwRTu1e6avJCkhPk4LP3xXm376QTcSElT2vhrq8PwABWTPYW1YpNri+R9qw7of9efxI/K221WqbAV1euZF5S9YOGnOhfPnNPf9idqxeYOux15VvgKhatPxadWs28i64LhjK75eqBXfLNK50yclSQVCi6pNp6dVqXptSdLKpV/o5x+X68iBfYq9dlUzvlglXz9/KyPjLly7eE47vpqtk3s2KzEhTn4586p6p77KUahE0pxLp45r+1ezdPbALjkciQoIKaTaTw2Rb47cFiZHWlowf57mzJqpc+fOqmSp0ho8dJjCKlSwOpZRKKv3qCP79+inZV8qf+HiLuOfz5iknZt+0TMvv6Gsvn5aMH2spkUO0ctvT7coKe7U7h1b1KzlYypeqpwSExM1f+ZkvTGop8bPXCifrFklSZPfek1Xr1zRoNfHKSAgSOtWLdO4NwbrrffmqkiJ0hbfAqRWjpy51eHpXgrJX1ByOrV2xVKNGTFAkVM+VsHCxRQXd10Vq4arYtVwLfjwPavj4i7EX7uilRNeVu4SFVT3hRGy+wXqypkT8s7qlzTnytmTWjnhZRUNb6LyzTvJyyebYk4dk6eXt4XJkZaWffetxrwdqVeHRygsrKLmzZ2jF557Wl9+s0zBwcFWxzMGywDuQddjr+nDsRHq3Guwsv3PWZXYq1f08w9fq+3TvVW6YlWFFi+tLn1e0aG9O3Vo7y4LE+NOvDp6sho0e0QFCxdT4WIl1fPlCJ07c0qH9kclzdm3e4eat3pcJUqXV558BfRo5+7y9fV3mYN7R5Xwurqvem3lzV9IeQuE6vFuPeSTNZsORP31+H2wTUe1bN9VJcqEWZwUdyvqh4XKFpRTNTr1VXBoKfkFhyikTGX55cqbNGfH0o+Ut2xVVWz5lLIXLCa/XHmVP6yGfPyDrAuONDV3ziy1adtOrVo/qmLFi+vV4RHy8fHRki8WWR3NKJTVe9CCaWNVvmotlalUzWX86IG9SrxxQ2Uq/jMeUqCwcuTKo0P7KKv3umtXr0iS/PwDksZKlaugX1Z/r8uXYuRwOPTzj8uVkBCnshWrWhUTacSRmKhffvxecddjVaIs5TSjObFzg3IUKqGfP4zUkqGdtPytF3Xwl2VJ250Oh07u3iT/3Pm0ZsowLRnaSSvG9tcfO9ZbmBppKSE+XlF7dqtmeK2kMQ8PD9WsWUs7tm+1MJl5LF8GEBUVpV9//VXh4eEqXbq09u7dq4kTJyouLk6dO3dWw4YNb3v9uLg4xcXFuYzFx8fJ29vuztiW2bh2hY4d2qchY2cm23bp4nllyeLlcrZVkvyDcujShej0igg3cDgcmj1ljEqVq6hCRf5Z+tF/2Fsa//pgPdWmoTw9PeVt99HAEWOUN39BC9Pibhw7fECv9XlKCfHx8smaVf2Hv6MCoUWtjoU0diX6lA6s+1alGrRS2SbtdP7Yfm1d9L48PL1UpEYjXb8SoxtxsYr6YaHCHnpCFR7pplNRm/XzzFFq0GuUcpfgHzD3ugsXLygxMTHZy/3BwcE6fPiQRanMZOmZ1WXLlqlSpUoaMGCA7rvvPi1btkx169bVgQMHdPToUTVt2lSrVq267T4iIyMVGBjo8jN/+oT0uQHp7PzZ0/rsgwl6qv8IeWXQMo6bmzFptI4fOah+r0a6jC+YNVVXr17Wa29P1egpH6tF284a9/pgHT2036KkuFv5CoRq9NR5en3SLDV++FFNfWeE/jjKH64Mx+lU9gLFVKFFF2UvWEzFaj+gouHNdPDnb/9/u0OSlD+spko1aKXsBYqqTJPHlK9cNR38+TsLgwPpz9KyOnLkSA0cOFDR0dGaNWuWOnbsqGeeeUYrVqzQypUrNXDgQI0ePfq2+xgyZIhiYmJcfjo+1zd9bkA6O3Zwry7HXNCoft3Uo1Ud9WhVR/t3bdWP33yuHq3qKCAoh27cSNC1K5ddrnf54nkFZGeh9r1qxrtvacuGdRo+ZrqCc+VJGj914riWffmpegwYrrDK1VW4WEk99uSzKlayrJZ/9bmFiXE3snh5KSR/QRUtWUYdnu6l0KIltGzxAqtjIY35BGRXQEghl7GAPAV17cJZSZK3b4BsHp4KCCmYbM7V/5+De1v2oOzy9PRUdLTrK5/R0dHKmTOnRanMZOkygN27d+ujjz6SJLVr105PPPGE2rZtm7S9U6dOmjVr1m33YbfbZbe7nmX09k5I+7AGKF2hqoa9O9dl7KOJbyqkQKiaPtpZOXLmkWeWLNq7Y5Mq12ogSTr1x1GdP3taRUuVtyIy7oLT6dTMyW/rt3U/KmLs+8qTN7/L9rjr1yVJNpvrvzk9PDzkcDjSLSfcy+FwKiEh3uoYSGM5i5bV5TN/uIxdPvunsmX/6yOpPLN4KUehErp8+s9kc/jYqozBy9tbZcqW04Zf16tho8aS/lrytWHDerXv0NnidGax/A1WNptN0l9/YH18fBQYGJi0zd/fXzExMVZFM45PNl/lDy3m8uPtk1W+/oHKH1pMWX39VLtxCy2cOUn7dmzW0QN79dGkN1W0dHkVLU1ZvdfMmDRaP/3wrfoMfVM+2bLpwvlzunD+nOLi/iqp+QsVVkj+gnp/wpvav3eXTp04rq8/n6sdWzaoeu361obHHflk5mRF7diis6dO6NjhA/9/ebNqN2wuSbp4/pyOHNynUyeOS5KOHz6gIwf36colnifvNSXrt1T0kX3a8/1nunz2hI5uWq2DvyxT8ToPJc0p3aiNjm/9SQd/WabLZ09o/9qvdWLXbyp+/4MWJkdaeqJLN32x8DN9tWSxDh08qDdGjlBsbKxatW5jdTSjWHpmtXDhwtq/f7+KFSsmSVq/fr0KFfrnZZFjx44pb968t7o6buKx7i/K5mHT9NFD//lSgBcGWB0Ld+D7rxdKkka89KzLeI+Bw9Wg2SPKksVLQ9+cpHkz3tVbr/bT9evXFJKvoHq+HKHKNe63IjLu0qWLFzTlnRG6eP6csmXzU6GixTV41LuqUKWGJOmHb77Qoo8/SJof8f//bzw/4DXVa9rCksy4M8GhJXV/91e04+s52r3sE/kG59F9bZ5R4WoNkuYUqFhLVdr1UNQPn2vrovflnzu/aj81VLmKlbMwOdLSA80f1IXz5zVl8iSdO3dWpUqX0ZTpMxTMMgAXNqfT6bTq4NOmTVPBggX10EMP3XT70KFDdebMGc2YMSNV+/1xH+98z0yCs/Fms8zkBkscMpUle09bHQHpaGijEv89CRmGTwpPmVpaVt2Fspq5UFYzF8pq5kJZzVwoq5lLSsuq5WtWAQAAgFuhrAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLFsTqfTaXWItHb5usPqCEhHXln4N1dmknCDx3dm4ulhszoC0pEH93em4pMlZfP4Kw8AAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7Kawcye+YGqViyjsW+PsjoK3GjB/Hlq3qShqt0Xpk7tH9POHTusjoR0wOM7Y5s5Y7o6tW+r2jUqq2G9Wur3Yk8dOXzI6lhwM57P/xtlNQPZvWunvlj4qUqULGV1FLjRsu++1Zi3I/Vcj55a8PlilSpVWi8897Sio6OtjgY34vGd8W3ZtFGPt++oj+Z9qqnvf6gbN27ohee6K/baNaujwU14Pk8ZymoGce3aVQ0bMlCvDB8p/4AAq+PAjebOmaU2bdupVetHVax4cb06PEI+Pj5a8sUiq6PBTXh8Zw7vTZuhR1q1UbHiJVSqVGlFvBGpUydPaM+e3VZHg5vwfJ4yxpVVp9NpdYR70lujXlftuvVUo2Ytq6PAjRLi4xW1Z7dqhv9zP3t4eKhmzVrasX2rhcngTjy+M6crVy5LkgIDAy1OAnfg+TzljCurdrtdUVFRVse4pyz/bqn2Ru1Rrxf7Wx0Fbnbh4gUlJiYqODjYZTw4OFjnzp2zKBXcicd35uRwODTmrVGqdF9lFS9R0uo4cAOez1Mui1UH7t//5k+8iYmJGj16dNKdN27cuNvuJy4uTnFxcS5j8U4v2e32tAlquFOnTmrs25F6b/rMTHObgcyCx3fmFfnmSB04sF+z5sy3OgpgOcvK6oQJE1SxYkUFBQW5jDudTkVFRcnX11c2m+0/9xMZGamIiAiXscGvvKahrw5Py7jG2rtnt86fj1bn9o8mjSUmJmrr5k36bMF8/bJxuzw9PS1MiLSUPSi7PD09ky2+j46OVs6cOS1KBXfh8Z05jX5zpH5as1ozZ3+sPCEhVseBm/B8nnKWldVRo0bp/fff19ixY9WwYcOkcS8vL82ePVtly5ZN0X6GDBmS7CxtvNMrTbOarFqNcC1Y+KXL2Mjhryi0cBF16dadP2QZjJe3t8qULacNv65Xw0aNJf31cuGGDevVvkNni9MhrfH4zlycTqfeGvW6Vq36QR98+JHyFyhgdSS4Ec/nKWdZWR08eLAaNWqkzp07q0WLFoqMjJSXV+pLpt1uT/by2OXrjrSKaTxfX99k65l8smZVUFAQ65wyqCe6dNOwoYNUrlx5lQ+roI/nzlFsbKxatW5jdTSkMR7fmUvkmyP13bffaPzE9+Tr66tz585Kkvz8/OXj42NxOrgDz+cpY1lZlaRq1app8+bN6tmzp6pWrap58+al6KV/IDN7oPmDunD+vKZMnqRz586qVOkymjJ9hoJ52Qi4p33+6SeSpGeeetJlPOL1UXqkFeUlI+L5PGVsTkM+K2rBggXq27evzp49q507d6Z4GcDNZKYzq5C8shj3oRZwo4QbPL4zE08PTmBkJh7c35mKTwpPmRpTViXpjz/+0ObNm9W4cWP5+vre8X4oq5kLZTVzoaxmLpTVzIWymrnck2U1rVBWMxfKauZCWc1cKKuZC2U1c0lpWeWvPAAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgLMoqAAAAjEVZBQAAgLEoqwAAADAWZRUAAADGoqwCAADAWJRVAAAAGIuyCgAAAGPZnE6n0+oQuHtxcXGKjIzUkCFDZLfbrY4DN+P+zly4vzMX7u/Mhfv7v1FWM4hLly4pMDBQMTExCggIsDoO3Iz7O3Ph/s5cuL8zF+7v/8YyAAAAABiLsgoAAABjUVYBAABgLMpqBmG32zV8+HAWZ2cS3N+ZC/d35sL9nblwf/833mAFAAAAY3FmFQAAAMairAIAAMBYlFUAAAAYi7IKAAAAY1FWM4j33ntPhQsXlo+Pj2rUqKHffvvN6khwg7Vr16pFixbKly+fbDablixZYnUkuFFkZKSqVasmf39/5c6dW61atdK+ffusjgU3mTp1qipUqKCAgAAFBAQoPDxc3333ndWxkE5Gjx4tm82mvn37Wh3FOJTVDODTTz9V//79NXz4cG3ZskUVK1ZUs2bNdObMGaujIY1dvXpVFStW1HvvvWd1FKSDNWvWqGfPnvr111+1YsUKJSQkqGnTprp69arV0eAGBQoU0OjRo7V582Zt2rRJDRs2VMuWLbV7926ro8HNNm7cqOnTp6tChQpWRzESH12VAdSoUUPVqlXT5MmTJUkOh0MFCxZU7969NXjwYIvTwV1sNpsWL16sVq1aWR0F6eTs2bPKnTu31qxZo7p161odB+kgR44ceuedd/T0009bHQVucuXKFVWuXFlTpkzRG2+8oUqVKmnChAlWxzIKZ1bvcfHx8dq8ebMaN26cNObh4aHGjRtr/fr1FiYDkNZiYmIk/VVgkLElJiZqwYIFunr1qsLDw62OAzfq2bOnHnroIZe/43CVxeoAuDvnzp1TYmKi8uTJ4zKeJ08e7d2716JUANKaw+FQ3759Vbt2bZUvX97qOHCTnTt3Kjw8XNevX5efn58WL16ssmXLWh0LbrJgwQJt2bJFGzdutDqK0SirAHAP6Nmzp3bt2qV169ZZHQVuVKpUKW3btk0xMTFauHChunTpojVr1lBYM6Djx4+rT58+WrFihXx8fKyOYzTK6j0uZ86c8vT01OnTp13GT58+rZCQEItSAUhLvXr10jfffKO1a9eqQIECVseBG3l7e6t48eKSpCpVqmjjxo2aOHGipk+fbnEypLXNmzfrzJkzqly5ctJYYmKi1q5dq8mTJysuLk6enp4WJjQHa1bvcd7e3qpSpYpWrlyZNOZwOLRy5UrWOQH3OKfTqV69emnx4sVatWqVihQpYnUkpDOHw6G4uDirY8ANGjVqpJ07d2rbtm1JP1WrVlWnTp20bds2iur/4MxqBtC/f3916dJFVatWVfXq1TVhwgRdvXpV3bp1szoa0tiVK1d04MCBpMuHDx/Wtm3blCNHDhUqVMjCZHCHnj17av78+fryyy/l7++vU6dOSZICAwOVNWtWi9MhrQ0ZMkTNmzdXoUKFdPnyZc2fP1+rV6/W8uXLrY4GN/D390+2/tzX11fBwcGsS/8XymoG8Pjjj+vs2bN67bXXdOrUKVWqVEnLli1L9qYr3Ps2bdqkBg0aJF3u37+/JKlLly6aPXu2RangLlOnTpUk1a9f32V81qxZ6tq1a/oHgludOXNGTz75pE6ePKnAwEBVqFBBy5cvV5MmTayOBliKz1kFAACAsVizCgAAAGNRVgEAAGAsyioAAACMRVkFAACAsSirAAAAMBZlFQAAAMairAIAAMBYlFUAAAAYi7IKAIbp2rWrWrVqlXS5fv366tu3b7rnWL16tWw2my5evJjuxwaAv1FWASCFunbtKpvNJpvNJm9vbxUvXlwjR47UjRs33HrcL774Qq+//nqK5lIwAWQ0WawOAAD3kgceeECzZs1SXFycvv32W/Xs2VNeXl4aMmSIy7z4+Hh5e3unyTFz5MiRJvsBgHsRZ1YBIBXsdrtCQkIUGhqqF154QY0bN9ZXX32V9NL9m2++qXz58qlUqVKSpOPHj6tdu3YKCgpSjhw51LJlSx05ciRpf4mJierfv7+CgoIUHBysl19+WU6n0+WY/14GEBcXp0GDBqlgwYKy2+0qXry4Zs6cqSNHjqhBgwaSpOzZs8tms6lr166SJIfDocjISBUpUkRZs2ZVxYoVtXDhQpfjfPvttypZsqSyZs2qBg0auOQEAKtQVgHgLmTNmlXx8fGSpJUrV2rfvn1asWKFvvnmGyUkJKhZs2by9/fXTz/9pJ9//ll+fn564IEHkq4zduxYzZ49Wx9++KHWrVun8+fPa/Hixbc95pNPPqlPPvlEkyZNUlRUlKZPny4/Pz8VLFhQixYtkiTt27dPJ0+e1MSJEyVJkZGR+uijjzRt2jTt3r1b/fr1U+fOnbVmzRpJf5XqNm3aqEWLFtq2bZu6d++uwYMHu+vXBgApxjIAALgDTqdTK1eu1PLly9W7d2+dPXtWvr6+mjFjRtLL/x9//LEcDodmzJghm80mSZo1a5aCgoK0evVqNW3aVBMmTNCQIUPUpk0bSdK0adO0fPnyWx73999/12effaYVK1aocePGkqSiRYsmbf97yUDu3LkVFBQk6a8zsaNGjdIPP/yg8PDwpOusW7dO06dPV7169TR16lQVK1ZMY8eOlSSVKlVKO3fu1FtvvZWGvzUASD3KKgCkwjfffCM/Pz8lJCTI4XCoY8eOGjFihHr27KmwsDCXdarbt2/XgQMH5O/v77KP69ev6+DBg4qJidHJkydVo0aNpG1ZsmRR1apVky0F+Nu2bdvk6empevXqpTjzgQMHdO3aNTVp0sRlPD4+Xvfdd58kKSoqyiWHpKRiCwBWoqwCQCo0aNBAU6dOlbe3t/Lly6csWf55GvX19XWZe+XKFVWpUkXz5s1Ltp9cuXLd0fGzZs2a6utcuXJFkrR06VLlz5/fZZvdbr+jHACQXiirAJAKvr6+Kl68eIrmVq5cWZ9++qly586tgICAm87JmzevNmzYoLp160qSbty4oc2bN6ty5co3nR8WFiaHw6E1a9YkLQP4X3+f2U1MTEwaK1u2rOx2u44dO3bLM7JlypTRV1995TL266+//veNBAA34w1WAOAmnTp1Us6cOdWyZUv99NNPOnz4sFavXq0XX3xRf/zxhySpT58+Gj16tJYsWaK9e/eqR48et/2M1MKFC6tLly566qmntGTJkqR9fvbZZ5Kk0NBQ2Ww2ffPNNzp79qyuXLkif39/DRgwQP369dOcOXN08OBBbdmyRe+++67mzJkjSXr++ee1f/9+DRw4UPv27dP8+fM1e/Zsd/+KAOA/UVYBwE2yZcumtWvXqlChQmrTpo3KlCmjp59+WtevX0860/rSSy/piSeeUJcuXRQeHi5/f3+1bt36tvudOnWq2rZtqx49eqh06dJ65plndPXqVUlS/vz5FRERocGDBytPnjzq1auXJOn111/XsGHDFBkZqTJlyuiBBx7Q0qVLVaRIEUlSoUKFtGjRIi1ZskQVK1bUtGnTNGrUKDf+dgAgZWzOW63iBwAAACzGmVUAAAAYi7IKAAAAY1FWAQAAYCzKKgAAAIxFWQUAAICxKKsAAAAwFmUVAAAAxqKsAgAAwFiUVQAAABiLsgoAAABjUVYBAABgrP8D0Sabu6bjtBQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64       182\n",
      "           1       0.58      0.70      0.64       121\n",
      "           2       0.44      0.31      0.36       154\n",
      "           3       0.63      0.40      0.49       165\n",
      "           4       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.54       632\n",
      "   macro avg       0.44      0.44      0.42       632\n",
      "weighted avg       0.54      0.54      0.52       632\n",
      "\n",
      "632 632\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "27/91 [=======>......................] - ETA: 0s - loss: 1.4151 - accuracy: 0.3183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4180 - accuracy: 0.3202\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3254\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3222\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3212\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4201 - accuracy: 0.3115\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4200 - accuracy: 0.3115\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4200 - accuracy: 0.3115\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4200 - accuracy: 0.3115\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4200 - accuracy: 0.3115\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.3115\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.3115\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.3115\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.3115\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4198 - accuracy: 0.3115\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4198 - accuracy: 0.3115\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4198 - accuracy: 0.3115\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4198 - accuracy: 0.3115\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4197 - accuracy: 0.3115\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4197 - accuracy: 0.3115\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4197 - accuracy: 0.3115\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4197 - accuracy: 0.3115\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4196 - accuracy: 0.3115\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4196 - accuracy: 0.3115\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4196 - accuracy: 0.3115\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4196 - accuracy: 0.3115\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.3115\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.3115\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.3115\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.3115\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.3115\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.3115\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.3115\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.3115\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.3115\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.3115\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4193 - accuracy: 0.3115\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4193 - accuracy: 0.3115\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4193 - accuracy: 0.3115\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4193 - accuracy: 0.3115\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4193 - accuracy: 0.3115\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4192 - accuracy: 0.3115\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.3115\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4190 - accuracy: 0.3115\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.3115\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.3115\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.3115\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.3115\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.3115\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.3115\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2856 - accuracy: 0.4096\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2698 - accuracy: 0.4200\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2691 - accuracy: 0.4263\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2715 - accuracy: 0.4232\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2705 - accuracy: 0.4110\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2672 - accuracy: 0.4194\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2599 - accuracy: 0.4270\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2607 - accuracy: 0.4273\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2662 - accuracy: 0.4294\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2655 - accuracy: 0.4239\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2600 - accuracy: 0.4214\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2639 - accuracy: 0.4221\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2585 - accuracy: 0.4270\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2580 - accuracy: 0.4228\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2610 - accuracy: 0.4214\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2642 - accuracy: 0.4249\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2570 - accuracy: 0.4325\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2597 - accuracy: 0.4200\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2584 - accuracy: 0.4280\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2570 - accuracy: 0.4263\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2573 - accuracy: 0.4305\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2587 - accuracy: 0.4246\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2534 - accuracy: 0.4239\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2616 - accuracy: 0.4218\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2514 - accuracy: 0.4332\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2545 - accuracy: 0.4218\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2590 - accuracy: 0.4183\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2567 - accuracy: 0.4204\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2526 - accuracy: 0.4353\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2561 - accuracy: 0.4221\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2544 - accuracy: 0.4315\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2533 - accuracy: 0.4256\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2565 - accuracy: 0.4259\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2526 - accuracy: 0.4305\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2544 - accuracy: 0.4232\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2506 - accuracy: 0.4246\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2469 - accuracy: 0.4308\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2526 - accuracy: 0.4225\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2497 - accuracy: 0.4305\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.4346\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.4242\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2502 - accuracy: 0.4305\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2496 - accuracy: 0.4287\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2469 - accuracy: 0.4360\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2500 - accuracy: 0.4232\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2492 - accuracy: 0.4287\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2475 - accuracy: 0.4357\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2506 - accuracy: 0.4273\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2495 - accuracy: 0.4284\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2451 - accuracy: 0.4343\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2469 - accuracy: 0.4336\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2443 - accuracy: 0.4322\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2443 - accuracy: 0.4301\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2455 - accuracy: 0.4374\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2472 - accuracy: 0.4298\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2488 - accuracy: 0.4325\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2523 - accuracy: 0.4225\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2418 - accuracy: 0.4322\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2402 - accuracy: 0.4360\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2450 - accuracy: 0.4384\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2384 - accuracy: 0.4398\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2459 - accuracy: 0.4242\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2362 - accuracy: 0.4402\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2391 - accuracy: 0.4464\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2452 - accuracy: 0.4253\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2418 - accuracy: 0.4370\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2409 - accuracy: 0.4256\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2448 - accuracy: 0.4329\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2371 - accuracy: 0.4287\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2435 - accuracy: 0.4305\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2399 - accuracy: 0.4346\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2419 - accuracy: 0.4298\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2369 - accuracy: 0.4325\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2429 - accuracy: 0.4346\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2407 - accuracy: 0.4416\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2390 - accuracy: 0.4204\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2382 - accuracy: 0.4422\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2385 - accuracy: 0.4343\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2413 - accuracy: 0.4246\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2378 - accuracy: 0.4395\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2404 - accuracy: 0.4280\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2394 - accuracy: 0.4325\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2421 - accuracy: 0.4266\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2405 - accuracy: 0.4315\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2415 - accuracy: 0.4377\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2373 - accuracy: 0.4374\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2385 - accuracy: 0.4332\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2393 - accuracy: 0.4364\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2313 - accuracy: 0.4381\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2389 - accuracy: 0.4256\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2353 - accuracy: 0.4339\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2347 - accuracy: 0.4377\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2363 - accuracy: 0.4357\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2330 - accuracy: 0.4398\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2321 - accuracy: 0.4377\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2325 - accuracy: 0.4336\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2322 - accuracy: 0.4485\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2330 - accuracy: 0.4426\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2332 - accuracy: 0.4454\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2365 - accuracy: 0.4426\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4266 - accuracy: 0.3254\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.3254\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4264 - accuracy: 0.3254\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4264 - accuracy: 0.3254\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4264 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.3254\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3254\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4259 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4259 - accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4259 - accuracy: 0.3254\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.3254\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.3254\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.3254\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.3254\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.3254\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.3254\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3254\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3254\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.3254\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.3254\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3254\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3254\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3254\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3254\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3254\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3254\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3254\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3254\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3254\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3254\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3254\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3254\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3254\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3254\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3254\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4242 - accuracy: 0.3254\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4242 - accuracy: 0.3254\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4242 - accuracy: 0.3254\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4242 - accuracy: 0.3254\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.3254\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.3254\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.3254\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3254\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3254\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3254\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4238 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4238 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4238 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4238 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4237 - accuracy: 0.3254\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4237 - accuracy: 0.3254\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4237 - accuracy: 0.3254\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2992 - accuracy: 0.4093\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2937 - accuracy: 0.4162\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2956 - accuracy: 0.4114\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2944 - accuracy: 0.4062\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2933 - accuracy: 0.4187\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2915 - accuracy: 0.4103\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2900 - accuracy: 0.4204\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2914 - accuracy: 0.4232\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2902 - accuracy: 0.4110\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2979 - accuracy: 0.4103\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2904 - accuracy: 0.4110\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2911 - accuracy: 0.4142\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2881 - accuracy: 0.4204\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2879 - accuracy: 0.4228\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2900 - accuracy: 0.4107\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2885 - accuracy: 0.4103\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2858 - accuracy: 0.4124\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2863 - accuracy: 0.4159\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2864 - accuracy: 0.4124\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2863 - accuracy: 0.4169\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2861 - accuracy: 0.4176\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2880 - accuracy: 0.4166\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2840 - accuracy: 0.4183\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2880 - accuracy: 0.4242\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2870 - accuracy: 0.4152\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2848 - accuracy: 0.4131\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2825 - accuracy: 0.4124\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2893 - accuracy: 0.4176\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2829 - accuracy: 0.4076\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2874 - accuracy: 0.4124\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2831 - accuracy: 0.4194\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2817 - accuracy: 0.4235\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2834 - accuracy: 0.4266\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2842 - accuracy: 0.4225\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2861 - accuracy: 0.4089\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2843 - accuracy: 0.4083\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2833 - accuracy: 0.4180\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2867 - accuracy: 0.4100\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.4173\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2827 - accuracy: 0.4110\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.4135\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2844 - accuracy: 0.4086\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2828 - accuracy: 0.4197\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2844 - accuracy: 0.4204\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2827 - accuracy: 0.4194\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2828 - accuracy: 0.4207\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2821 - accuracy: 0.4211\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2829 - accuracy: 0.4096\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2811 - accuracy: 0.4145\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2830 - accuracy: 0.4207\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2836 - accuracy: 0.4194\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2862 - accuracy: 0.4214\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2844 - accuracy: 0.4162\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2808 - accuracy: 0.4228\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2809 - accuracy: 0.4225\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2850 - accuracy: 0.4176\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2852 - accuracy: 0.4159\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2822 - accuracy: 0.4187\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2807 - accuracy: 0.4246\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2805 - accuracy: 0.4148\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2802 - accuracy: 0.4256\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2800 - accuracy: 0.4159\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2807 - accuracy: 0.4190\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2800 - accuracy: 0.4162\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2818 - accuracy: 0.4128\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2800 - accuracy: 0.4135\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2798 - accuracy: 0.4225\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2775 - accuracy: 0.4159\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2813 - accuracy: 0.4204\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2793 - accuracy: 0.4093\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2793 - accuracy: 0.4239\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2782 - accuracy: 0.4145\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2798 - accuracy: 0.4152\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2794 - accuracy: 0.4183\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2793 - accuracy: 0.4284\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2828 - accuracy: 0.4235\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2807 - accuracy: 0.4200\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2786 - accuracy: 0.4180\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2809 - accuracy: 0.4187\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2823 - accuracy: 0.4159\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2803 - accuracy: 0.4162\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2847 - accuracy: 0.4166\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2802 - accuracy: 0.4176\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2772 - accuracy: 0.4190\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2853 - accuracy: 0.4259\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2795 - accuracy: 0.4128\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2779 - accuracy: 0.4225\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2769 - accuracy: 0.4211\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2765 - accuracy: 0.4176\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2777 - accuracy: 0.4135\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2779 - accuracy: 0.4190\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2762 - accuracy: 0.4214\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2774 - accuracy: 0.4121\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2780 - accuracy: 0.4214\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2759 - accuracy: 0.4239\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2769 - accuracy: 0.4256\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2819 - accuracy: 0.4145\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2772 - accuracy: 0.4197\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2779 - accuracy: 0.4249\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2784 - accuracy: 0.4204\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4178 - accuracy: 0.3254\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3254\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4161 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.3254\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4178 - accuracy: 0.3236\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3212\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3195\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3125\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3195\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3174\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4175 - accuracy: 0.3139\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3205\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4182 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3212\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3184\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3184\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3132\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3219\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3177\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3143\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3170\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3146\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3226\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3177\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4175 - accuracy: 0.3153\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3143\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3208\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3226\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3174\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3181\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3118\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3188\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4175 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3222\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3181\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4177 - accuracy: 0.3191\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3243\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3195\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3170\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3177\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4176 - accuracy: 0.3091\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3264\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4176 - accuracy: 0.3136\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3233\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3254\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3139\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4175 - accuracy: 0.3191\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4176 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3125\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4178 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3163\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3191\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3222\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3212\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3202\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3056\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4168 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3247\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4177 - accuracy: 0.3181\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3226\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3212\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3257\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3153\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3170\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4173 - accuracy: 0.3170\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3215\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3052\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4174 - accuracy: 0.3132\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4176 - accuracy: 0.3153\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3202\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.3167\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3215\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.3181\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3292\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3132\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4177 - accuracy: 0.3254\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3254\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4167 - accuracy: 0.3254\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3219\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3250\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3250\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3236\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3215\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3247\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3240\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3215\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4165 - accuracy: 0.3254\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.3254\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.3254\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.3559\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4009 - accuracy: 0.3562\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4008 - accuracy: 0.3562\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4005 - accuracy: 0.3593\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4005 - accuracy: 0.3604\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4004 - accuracy: 0.3580\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4004 - accuracy: 0.3587\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.3555\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4002 - accuracy: 0.3566\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.3562\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3569\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3576\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3593\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3573\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3576\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3600\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3590\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3580\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3580\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3562\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3580\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3559\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3590\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3583\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3580\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3531\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3587\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3562\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3548\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3576\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3566\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3573\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3573\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3562\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3583\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3559\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3573\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3597\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3569\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3576\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3573\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3541\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3593\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3562\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3569\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3597\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3587\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3562\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3566\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3545\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3559\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3576\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3566\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3590\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3576\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3587\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3569\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3580\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3583\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3573\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3593\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3593\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3562\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3993 - accuracy: 0.3580\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3573\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3583\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3576\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3566\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3548\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3576\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3593\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3548\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3580\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3566\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3590\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3587\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3580\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3590\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3580\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3566\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3569\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3604\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3604\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3566\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3576\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3607\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3593\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3587\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3573\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3990 - accuracy: 0.3573\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3621\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3583\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3988 - accuracy: 0.3600\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3569\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3593\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3573\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3573\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3566\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3989 - accuracy: 0.3531\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3988 - accuracy: 0.3597\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3986 - accuracy: 0.3517\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3979 - accuracy: 0.3458\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3975 - accuracy: 0.3507\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.3524\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3528\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3974 - accuracy: 0.3496\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.3548\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3971 - accuracy: 0.3503\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.3507\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.3489\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.3500\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3500\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3496\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3507\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3521\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3971 - accuracy: 0.3503\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3972 - accuracy: 0.3535\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3971 - accuracy: 0.3507\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3503\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3514\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3514\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3517\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3496\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3503\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.3541\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3545\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3535\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3517\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3517\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3535\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3969 - accuracy: 0.3496\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3535\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3510\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3517\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3524\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3510\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3531\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3517\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3548\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.3517\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3524\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3535\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3510\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3521\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3496\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3496\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3555\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3517\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.3535\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3503\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3528\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3507\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3538\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3545\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3531\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3521\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3965 - accuracy: 0.3531\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3535\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3965 - accuracy: 0.3552\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3966 - accuracy: 0.3541\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3531\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3517\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3517\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3965 - accuracy: 0.3541\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3521\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3521\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3541\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3552\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.3528\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3548\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.3535\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3514\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.3528\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3545\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3965 - accuracy: 0.3510\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.3514\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3538\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3531\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3528\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3528\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3538\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3500\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.3514\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3535\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.3541\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3961 - accuracy: 0.3535\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3961 - accuracy: 0.3528\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3961 - accuracy: 0.3531\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3961 - accuracy: 0.3510\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3510\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3961 - accuracy: 0.3541\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3514\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3531\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3531\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3531\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3486\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3521\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.3521\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3959 - accuracy: 0.3507\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3959 - accuracy: 0.3531\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.3167\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4239 - accuracy: 0.3184\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4236 - accuracy: 0.3198\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4235 - accuracy: 0.3163\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4235 - accuracy: 0.3174\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4233 - accuracy: 0.3188\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4232 - accuracy: 0.3181\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4231 - accuracy: 0.3177\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4230 - accuracy: 0.3184\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4229 - accuracy: 0.3184\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4229 - accuracy: 0.3181\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4228 - accuracy: 0.3195\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4228 - accuracy: 0.3181\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4227 - accuracy: 0.3195\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.3191\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.4225 - accuracy: 0.3181\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.3202\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.3195\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4227 - accuracy: 0.3188\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4225 - accuracy: 0.3184\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.3188\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.3181\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.3215\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.3170\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4222 - accuracy: 0.3212\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.3191\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4222 - accuracy: 0.3188\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3195\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3167\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3195\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3202\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3212\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3184\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3188\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3188\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3188\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3188\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.3208\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4220 - accuracy: 0.3191\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4219 - accuracy: 0.3215\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3208\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4219 - accuracy: 0.3195\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3184\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4219 - accuracy: 0.3198\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3188\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3195\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3208\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3198\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.3208\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4217 - accuracy: 0.3195\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4217 - accuracy: 0.3170\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4217 - accuracy: 0.3202\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4217 - accuracy: 0.3212\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3212\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3191\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3198\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3212\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3202\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3195\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3195\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3195\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.3208\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3198\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3212\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3212\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3191\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3222\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.3208\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3219\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3198\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3205\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3202\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3202\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3205\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3198\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.4215 - accuracy: 0.3202\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3202\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3205\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.3205\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3208\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3198\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3219\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3184\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3198\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3202\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3205\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3195\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3188\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.3188\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3188\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3212\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3208\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3208\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3208\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4211 - accuracy: 0.3195\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3195\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4211 - accuracy: 0.3208\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4211 - accuracy: 0.3195\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.3212\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4211 - accuracy: 0.3208\n",
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61        15\n",
      "           1       0.48      0.63      0.55        19\n",
      "           2       0.36      0.20      0.26        20\n",
      "           3       0.53      0.60      0.56        30\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.50        88\n",
      "   macro avg       0.39      0.42      0.39        88\n",
      "weighted avg       0.46      0.50      0.47        88\n",
      "\n",
      "88 88\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4059 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4057 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1.3590 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4054 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4052 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4049 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4047 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4046 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4043 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4041 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4039 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4038 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4037 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4035 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4034 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4033 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4032 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4031 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4059 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4053 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4050 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4047 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4044 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4042 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4040 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4038 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4037 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4035 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4033 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4032 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4031 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4073 - accuracy: 0.3004\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.3004\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4071 - accuracy: 0.3004\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3004\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3004\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3004\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3004\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3004\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3202\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4070 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4066 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4063 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3615 - accuracy: 0.3458\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3264 - accuracy: 0.3755\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3073 - accuracy: 0.4091\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2954 - accuracy: 0.4032\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2968 - accuracy: 0.4091\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2924 - accuracy: 0.4012\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2878 - accuracy: 0.4051\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2728 - accuracy: 0.3992\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2752 - accuracy: 0.4071\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2629 - accuracy: 0.4190\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2678 - accuracy: 0.4289\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2623 - accuracy: 0.4209\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2654 - accuracy: 0.4111\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2582 - accuracy: 0.4130\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2568 - accuracy: 0.4032\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.4190\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2525 - accuracy: 0.4190\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2456 - accuracy: 0.4209\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2561 - accuracy: 0.4170\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2442 - accuracy: 0.4249\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2474 - accuracy: 0.4170\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2433 - accuracy: 0.3972\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2394 - accuracy: 0.4170\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2379 - accuracy: 0.4170\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2352 - accuracy: 0.4032\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2481 - accuracy: 0.4190\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2407 - accuracy: 0.4012\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2359 - accuracy: 0.4190\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2375 - accuracy: 0.4032\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2286 - accuracy: 0.4111\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2323 - accuracy: 0.4328\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2282 - accuracy: 0.4308\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2326 - accuracy: 0.4328\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2226 - accuracy: 0.4150\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2150 - accuracy: 0.4308\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2267 - accuracy: 0.4130\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2232 - accuracy: 0.4308\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2247 - accuracy: 0.4209\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2261 - accuracy: 0.4032\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2229 - accuracy: 0.4170\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2285 - accuracy: 0.4170\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2176 - accuracy: 0.4289\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2088 - accuracy: 0.4229\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2221 - accuracy: 0.4111\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2062 - accuracy: 0.4170\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2064 - accuracy: 0.4269\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2120 - accuracy: 0.4328\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2138 - accuracy: 0.4190\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2123 - accuracy: 0.4249\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2219 - accuracy: 0.4229\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2177 - accuracy: 0.4289\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2110 - accuracy: 0.4130\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2099 - accuracy: 0.4249\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2120 - accuracy: 0.4387\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2010 - accuracy: 0.4387\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1970 - accuracy: 0.4328\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2095 - accuracy: 0.4269\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1993 - accuracy: 0.4130\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2105 - accuracy: 0.4328\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2001 - accuracy: 0.4269\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2032 - accuracy: 0.4447\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1996 - accuracy: 0.4289\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1920 - accuracy: 0.4328\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2036 - accuracy: 0.4269\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1984 - accuracy: 0.4249\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1983 - accuracy: 0.4289\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1982 - accuracy: 0.4387\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2019 - accuracy: 0.4486\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1919 - accuracy: 0.4249\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1938 - accuracy: 0.4308\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1828 - accuracy: 0.4387\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1977 - accuracy: 0.4328\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1895 - accuracy: 0.4348\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1824 - accuracy: 0.4407\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1861 - accuracy: 0.4506\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1977 - accuracy: 0.4249\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1885 - accuracy: 0.4091\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1892 - accuracy: 0.4368\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1898 - accuracy: 0.4289\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1868 - accuracy: 0.4407\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.4190\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1818 - accuracy: 0.4407\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1799 - accuracy: 0.4447\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1925 - accuracy: 0.4209\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.4545\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1874 - accuracy: 0.4526\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1851 - accuracy: 0.4407\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1826 - accuracy: 0.4585\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1804 - accuracy: 0.4644\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1709 - accuracy: 0.4447\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1826 - accuracy: 0.4486\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1696 - accuracy: 0.4407\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1769 - accuracy: 0.4387\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1737 - accuracy: 0.4427\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1737 - accuracy: 0.4486\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1844 - accuracy: 0.4308\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1691 - accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1764 - accuracy: 0.4466\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1815 - accuracy: 0.4348\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1657 - accuracy: 0.4585\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4122 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4116 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3571 - accuracy: 0.3498\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3478 - accuracy: 0.3518\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3411 - accuracy: 0.3518\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3397 - accuracy: 0.3735\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3372 - accuracy: 0.3676\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3368 - accuracy: 0.3715\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3334 - accuracy: 0.3775\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3286 - accuracy: 0.3854\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3280 - accuracy: 0.3834\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3264 - accuracy: 0.3696\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3260 - accuracy: 0.3794\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3278 - accuracy: 0.3656\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3245 - accuracy: 0.3735\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3245 - accuracy: 0.3854\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3235 - accuracy: 0.3656\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3217 - accuracy: 0.3715\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3215 - accuracy: 0.3676\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3200 - accuracy: 0.3735\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3197 - accuracy: 0.3735\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3236 - accuracy: 0.3696\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3177 - accuracy: 0.3755\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3162 - accuracy: 0.3715\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3153 - accuracy: 0.3794\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3151 - accuracy: 0.3775\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3170 - accuracy: 0.3636\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3155 - accuracy: 0.3834\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3143 - accuracy: 0.3834\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3126 - accuracy: 0.3775\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3154 - accuracy: 0.3814\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3130 - accuracy: 0.3696\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3198 - accuracy: 0.3933\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3108 - accuracy: 0.3676\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3086 - accuracy: 0.3775\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3115 - accuracy: 0.3834\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3079 - accuracy: 0.3775\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3137 - accuracy: 0.3735\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3090 - accuracy: 0.3656\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3088 - accuracy: 0.3834\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3056 - accuracy: 0.3814\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3105 - accuracy: 0.3656\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3073 - accuracy: 0.3794\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3067 - accuracy: 0.3834\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3045 - accuracy: 0.3775\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3112 - accuracy: 0.3874\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3037 - accuracy: 0.3913\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3026 - accuracy: 0.3854\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3030 - accuracy: 0.3775\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3002 - accuracy: 0.3814\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3021 - accuracy: 0.3834\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3046 - accuracy: 0.3834\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3029 - accuracy: 0.4012\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2984 - accuracy: 0.3972\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3011 - accuracy: 0.3735\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3006 - accuracy: 0.3794\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3025 - accuracy: 0.3715\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2977 - accuracy: 0.3933\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2998 - accuracy: 0.3953\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2995 - accuracy: 0.3775\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2986 - accuracy: 0.3854\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3051 - accuracy: 0.3854\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3006 - accuracy: 0.4091\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2952 - accuracy: 0.3972\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2914 - accuracy: 0.4051\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2936 - accuracy: 0.3854\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2930 - accuracy: 0.3913\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2986 - accuracy: 0.4111\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2908 - accuracy: 0.4051\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2926 - accuracy: 0.3874\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2920 - accuracy: 0.4051\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2893 - accuracy: 0.3913\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2947 - accuracy: 0.4071\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2936 - accuracy: 0.3933\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2887 - accuracy: 0.4012\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2880 - accuracy: 0.4032\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2911 - accuracy: 0.3755\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2889 - accuracy: 0.3913\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2906 - accuracy: 0.4071\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2887 - accuracy: 0.4091\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2882 - accuracy: 0.3953\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2855 - accuracy: 0.3953\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2853 - accuracy: 0.4051\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2880 - accuracy: 0.3933\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2862 - accuracy: 0.3933\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2889 - accuracy: 0.3933\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2884 - accuracy: 0.3913\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2859 - accuracy: 0.4012\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2889 - accuracy: 0.4229\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2842 - accuracy: 0.4032\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2867 - accuracy: 0.4170\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.4071\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2829 - accuracy: 0.3992\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2900 - accuracy: 0.4150\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2815 - accuracy: 0.4091\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2795 - accuracy: 0.4091\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2913 - accuracy: 0.4111\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2812 - accuracy: 0.4190\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2831 - accuracy: 0.4091\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2801 - accuracy: 0.3953\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2802 - accuracy: 0.4071\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2794 - accuracy: 0.4111\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4060 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4057 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4053 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4051 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4049 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4046 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4044 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4042 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4040 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4038 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4037 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4035 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4034 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4034 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4032 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4031 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4041 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4036 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4031 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4019 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4056 - accuracy: 0.3419\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4050 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4045 - accuracy: 0.3419\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4042 - accuracy: 0.3419\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4039 - accuracy: 0.3419\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4037 - accuracy: 0.3419\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4034 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4033 - accuracy: 0.3419\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4032 - accuracy: 0.3419\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4030 - accuracy: 0.3419\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4029 - accuracy: 0.3419\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3419\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.3419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.3419\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3419\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4022 - accuracy: 0.3419\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3419\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3870 - accuracy: 0.3320\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3865 - accuracy: 0.3419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3859 - accuracy: 0.3458\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3854 - accuracy: 0.3439\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3851 - accuracy: 0.3498\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3849 - accuracy: 0.3498\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3846 - accuracy: 0.3458\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3843 - accuracy: 0.3518\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3842 - accuracy: 0.3538\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3842 - accuracy: 0.3538\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.3538\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.3518\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3837 - accuracy: 0.3538\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3837 - accuracy: 0.3577\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3837 - accuracy: 0.3557\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3836 - accuracy: 0.3557\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.3597\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.3617\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3834 - accuracy: 0.3597\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3834 - accuracy: 0.3577\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3833 - accuracy: 0.3557\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3834 - accuracy: 0.3538\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3834 - accuracy: 0.3577\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.3557\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.3597\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3832 - accuracy: 0.3518\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3832 - accuracy: 0.3538\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3832 - accuracy: 0.3538\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3557\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3557\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3577\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.3538\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3832 - accuracy: 0.3577\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3577\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3831 - accuracy: 0.3577\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3829 - accuracy: 0.3577\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.3577\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3577\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3557\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3829 - accuracy: 0.3538\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.3577\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.3557\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.3557\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3577\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3557\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3829 - accuracy: 0.3577\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3829 - accuracy: 0.3577\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3557\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.3557\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3557\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3577\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.3557\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3577\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3557\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.3538\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.3577\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3577\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.3597\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.3577\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3557\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3557\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.3577\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3827 - accuracy: 0.3557\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3826 - accuracy: 0.3577\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3557\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3577\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3577\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3557\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3597\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3557\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3538\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3577\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3617\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3577\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.3577\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3577\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3577\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3577\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3538\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.3557\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3597\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3577\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3577\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3825 - accuracy: 0.3577\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3557\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3577\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3597\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3577\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3557\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3577\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3577\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3577\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.3538\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3597\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.3538\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3577\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3597\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.3557\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.3577\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.3597\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3910 - accuracy: 0.3538\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3904 - accuracy: 0.3557\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3897 - accuracy: 0.3538\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3892 - accuracy: 0.3538\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3888 - accuracy: 0.3518\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3886 - accuracy: 0.3518\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3883 - accuracy: 0.3518\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3881 - accuracy: 0.3557\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3879 - accuracy: 0.3538\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3876 - accuracy: 0.3597\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3875 - accuracy: 0.3538\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3873 - accuracy: 0.3577\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3872 - accuracy: 0.3577\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3871 - accuracy: 0.3498\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3870 - accuracy: 0.3538\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3870 - accuracy: 0.3518\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3868 - accuracy: 0.3478\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3867 - accuracy: 0.3458\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3866 - accuracy: 0.3478\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3868 - accuracy: 0.3478\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3867 - accuracy: 0.3518\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3866 - accuracy: 0.3498\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3865 - accuracy: 0.3538\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3867 - accuracy: 0.3518\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3867 - accuracy: 0.3557\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3865 - accuracy: 0.3557\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3866 - accuracy: 0.3636\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3577\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3498\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3557\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3518\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3538\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3538\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.3518\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3577\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3864 - accuracy: 0.3538\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3538\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3538\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3557\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3557\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3557\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3577\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3538\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3557\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3863 - accuracy: 0.3518\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3538\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3538\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3557\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3518\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3557\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3518\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3498\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3538\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3863 - accuracy: 0.3538\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3557\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3498\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3538\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3538\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.3577\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3538\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3498\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3557\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3861 - accuracy: 0.3518\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3859 - accuracy: 0.3597\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3518\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3538\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3858 - accuracy: 0.3518\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3518\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3859 - accuracy: 0.3557\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3859 - accuracy: 0.3538\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3859 - accuracy: 0.3557\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.3577\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3498\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3859 - accuracy: 0.3538\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3518\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3557\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3498\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3597\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3617\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3538\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3518\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3557\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3518\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3577\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3597\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3857 - accuracy: 0.3518\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3857 - accuracy: 0.3597\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.3577\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3858 - accuracy: 0.3557\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3856 - accuracy: 0.3557\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4282 - accuracy: 0.3162\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4280 - accuracy: 0.3162\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4276 - accuracy: 0.3182\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4274 - accuracy: 0.3202\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4272 - accuracy: 0.3182\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4270 - accuracy: 0.3202\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4269 - accuracy: 0.3142\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4269 - accuracy: 0.3182\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4268 - accuracy: 0.3182\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4266 - accuracy: 0.3142\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4266 - accuracy: 0.3142\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.3142\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.3162\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.3162\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.3202\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3221\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3221\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.3221\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4259 - accuracy: 0.3221\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.3182\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.3202\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.3202\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3202\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.3182\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3182\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3202\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.3202\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4256 - accuracy: 0.3142\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.3182\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3162\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3202\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.3182\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3202\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3202\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3202\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3182\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.3162\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3162\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3202\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4251 - accuracy: 0.3142\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3162\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4253 - accuracy: 0.3182\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3162\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3182\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3182\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4252 - accuracy: 0.3162\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3142\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3162\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.3202\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3182\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3162\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.3162\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3142\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4250 - accuracy: 0.3123\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4250 - accuracy: 0.3142\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3202\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3202\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3162\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3202\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3162\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3162\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4249 - accuracy: 0.3142\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3142\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3182\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4248 - accuracy: 0.3142\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4248 - accuracy: 0.3142\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3142\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3162\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3123\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3162\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3182\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3162\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.3162\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.3162\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4246 - accuracy: 0.3142\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3162\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3182\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3162\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4244 - accuracy: 0.3142\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3162\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3182\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3162\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3142\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3202\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.3142\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3162\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.3162\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4242 - accuracy: 0.3162\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.3142\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.12      1.00      0.22         1\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.41        17\n",
      "   macro avg       0.51      0.69      0.47        17\n",
      "weighted avg       0.68      0.41      0.45        17\n",
      "\n",
      "17 17\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4033 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4032 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4030 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4029 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4026 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4022 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4022 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4021 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4017 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_109 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4034 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4034 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4027 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4021 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4017 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4017 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.2955\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4000 - accuracy: 0.3182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3991 - accuracy: 0.3068\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 20)                20        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4344 - accuracy: 0.3409\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3286 - accuracy: 0.3182\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3155 - accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2761 - accuracy: 0.3295\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2501 - accuracy: 0.4205\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2149 - accuracy: 0.4091\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1992 - accuracy: 0.4091\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1922 - accuracy: 0.4205\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1872 - accuracy: 0.4318\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1787 - accuracy: 0.4205\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1877 - accuracy: 0.4659\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1717 - accuracy: 0.4773\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1431 - accuracy: 0.4545\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1545 - accuracy: 0.4886\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1641 - accuracy: 0.4659\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1470 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1281 - accuracy: 0.4773\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1375 - accuracy: 0.4659\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1446 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1247 - accuracy: 0.4318\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1174 - accuracy: 0.5227\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1145 - accuracy: 0.4432\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1179 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1110 - accuracy: 0.4545\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1047 - accuracy: 0.4886\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1170 - accuracy: 0.4773\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0898 - accuracy: 0.4773\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0853 - accuracy: 0.5341\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0882 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0989 - accuracy: 0.4545\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0831 - accuracy: 0.5114\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0773 - accuracy: 0.4318\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0687 - accuracy: 0.4773\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.5341\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0576 - accuracy: 0.5341\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0469 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0445 - accuracy: 0.5114\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0666 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0556 - accuracy: 0.4886\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0482 - accuracy: 0.5227\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.4886\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0381 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.5227\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0467 - accuracy: 0.4773\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0326 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0409 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0317 - accuracy: 0.4886\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0498 - accuracy: 0.5114\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.5227\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.4886\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.4886\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0111 - accuracy: 0.5114\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0051 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0176 - accuracy: 0.4659\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.5114\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0026 - accuracy: 0.4886\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9966 - accuracy: 0.5341\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.4886\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.5227\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9989 - accuracy: 0.5341\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.5227\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9720 - accuracy: 0.5568\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9717 - accuracy: 0.5227\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9767 - accuracy: 0.4886\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9709 - accuracy: 0.5114\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9809 - accuracy: 0.5341\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9612 - accuracy: 0.5455\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.5341\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9978 - accuracy: 0.4886\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.5341\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9603 - accuracy: 0.5227\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9601 - accuracy: 0.5568\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9733 - accuracy: 0.5568\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9587 - accuracy: 0.5341\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9515 - accuracy: 0.5455\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.5455\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9564 - accuracy: 0.5227\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9372 - accuracy: 0.5682\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9439 - accuracy: 0.5682\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9524 - accuracy: 0.5227\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9335 - accuracy: 0.5455\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.5455\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.5568\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9328 - accuracy: 0.5682\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9390 - accuracy: 0.5568\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.5568\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9266 - accuracy: 0.5455\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9303 - accuracy: 0.5682\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9213 - accuracy: 0.5455\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9194 - accuracy: 0.5795\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9507 - accuracy: 0.5682\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.5682\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9077 - accuracy: 0.5795\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9296 - accuracy: 0.5682\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8951 - accuracy: 0.6136\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9038 - accuracy: 0.5909\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9077 - accuracy: 0.5682\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.5568\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3387 - accuracy: 0.4205\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3240 - accuracy: 0.3864\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3052 - accuracy: 0.3636\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2919 - accuracy: 0.3864\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2907 - accuracy: 0.4545\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2924 - accuracy: 0.4545\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2885 - accuracy: 0.4545\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2816 - accuracy: 0.4545\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2736 - accuracy: 0.4659\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2717 - accuracy: 0.4545\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2705 - accuracy: 0.4318\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2677 - accuracy: 0.4545\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2609 - accuracy: 0.4659\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.4886\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2519 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2505 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2484 - accuracy: 0.5227\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.5341\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.5227\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2404 - accuracy: 0.5227\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2385 - accuracy: 0.5227\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2349 - accuracy: 0.5114\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2353 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2320 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2311 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2300 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2276 - accuracy: 0.4659\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2254 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2236 - accuracy: 0.5227\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2192 - accuracy: 0.5114\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2174 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2165 - accuracy: 0.5341\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2176 - accuracy: 0.5341\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2167 - accuracy: 0.5227\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2110 - accuracy: 0.5227\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2120 - accuracy: 0.5341\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2121 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2099 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2083 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2052 - accuracy: 0.5114\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2066 - accuracy: 0.5114\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2051 - accuracy: 0.5114\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2044 - accuracy: 0.5114\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2039 - accuracy: 0.5227\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2007 - accuracy: 0.5227\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2053 - accuracy: 0.4886\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1988 - accuracy: 0.5227\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1974 - accuracy: 0.5227\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1990 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1982 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1959 - accuracy: 0.5114\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1964 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1937 - accuracy: 0.5114\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1944 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1921 - accuracy: 0.5114\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1925 - accuracy: 0.5114\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1913 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1890 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1887 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1885 - accuracy: 0.5114\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1891 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1875 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1851 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1852 - accuracy: 0.4886\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1857 - accuracy: 0.4886\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1832 - accuracy: 0.4886\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.5114\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1814 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1816 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1847 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1821 - accuracy: 0.5114\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1784 - accuracy: 0.4886\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1782 - accuracy: 0.4773\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1783 - accuracy: 0.4773\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1764 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1764 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1753 - accuracy: 0.5114\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1751 - accuracy: 0.5114\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1736 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1731 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1741 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1748 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1724 - accuracy: 0.4886\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1743 - accuracy: 0.4886\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1708 - accuracy: 0.5114\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1726 - accuracy: 0.5227\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1712 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1689 - accuracy: 0.4886\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1691 - accuracy: 0.4773\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1674 - accuracy: 0.4886\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1686 - accuracy: 0.4886\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1693 - accuracy: 0.4886\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1681 - accuracy: 0.4773\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1658 - accuracy: 0.4886\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1652 - accuracy: 0.4886\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1645 - accuracy: 0.4886\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1674 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1632 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4030 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4030 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4029 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4029 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4026 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4026 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4024 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4022 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4022 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4021 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4017 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4017 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4013 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3068\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3068\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3068\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4031 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4016 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3995 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.3182\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3990 - accuracy: 0.3182\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3988 - accuracy: 0.3182\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3987 - accuracy: 0.3182\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3989 - accuracy: 0.3182\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3987 - accuracy: 0.3182\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3985 - accuracy: 0.3182\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3985 - accuracy: 0.3182\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3985 - accuracy: 0.3182\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3984 - accuracy: 0.3182\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3985 - accuracy: 0.3182\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3984 - accuracy: 0.3182\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3983 - accuracy: 0.3182\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3984 - accuracy: 0.3182\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3983 - accuracy: 0.3182\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3986 - accuracy: 0.3182\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3984 - accuracy: 0.3182\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3987 - accuracy: 0.3182\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3983 - accuracy: 0.3182\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3984 - accuracy: 0.3182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3985 - accuracy: 0.3182\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3986 - accuracy: 0.3182\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3982 - accuracy: 0.3182\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.3182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.3182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.3182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3977 - accuracy: 0.3182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3978 - accuracy: 0.3182\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4036 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4036 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4029 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4024 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4022 - accuracy: 0.3068\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4020 - accuracy: 0.3068\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4021 - accuracy: 0.3068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.3068\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3068\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4015 - accuracy: 0.3068\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4014 - accuracy: 0.3068\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.3068\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4010 - accuracy: 0.3068\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4008 - accuracy: 0.3068\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4007 - accuracy: 0.3068\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4005 - accuracy: 0.3068\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.3068\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4003 - accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.3068\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.2386\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.2955\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.2159\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.3182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3998 - accuracy: 0.3182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3999 - accuracy: 0.3182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3999 - accuracy: 0.3182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3999 - accuracy: 0.3182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3998 - accuracy: 0.3182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3999 - accuracy: 0.3182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3993 - accuracy: 0.3182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3997 - accuracy: 0.3182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.3182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3993 - accuracy: 0.3182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.3182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.3182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.3182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3993 - accuracy: 0.3182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3993 - accuracy: 0.3182\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.3750\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3541 - accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3541 - accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3541 - accuracy: 0.3750\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3538 - accuracy: 0.3864\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3539 - accuracy: 0.3750\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3539 - accuracy: 0.3864\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3539 - accuracy: 0.3864\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3537 - accuracy: 0.3750\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.3864\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3540 - accuracy: 0.3864\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3536 - accuracy: 0.3864\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.3977\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.3864\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.3977\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.3864\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3533 - accuracy: 0.3864\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3532 - accuracy: 0.3977\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.3977\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.3977\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.3864\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3533 - accuracy: 0.3977\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3531 - accuracy: 0.3977\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3533 - accuracy: 0.3864\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3534 - accuracy: 0.3864\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3864\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3531 - accuracy: 0.3864\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3531 - accuracy: 0.3864\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3531 - accuracy: 0.3864\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3531 - accuracy: 0.3864\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3864\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3864\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3864\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3864\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3529 - accuracy: 0.3864\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.3864\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3528 - accuracy: 0.3977\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3977\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3525 - accuracy: 0.3977\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3526 - accuracy: 0.3977\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3525 - accuracy: 0.3977\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3528 - accuracy: 0.4091\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.4091\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.3977\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.3864\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.3977\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.3977\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3864\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3523 - accuracy: 0.4091\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.3864\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.3977\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3523 - accuracy: 0.4091\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.3977\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3523 - accuracy: 0.3977\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3523 - accuracy: 0.3977\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3523 - accuracy: 0.3977\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3523 - accuracy: 0.4091\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3522 - accuracy: 0.4091\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3522 - accuracy: 0.4091\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3526 - accuracy: 0.3864\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4205\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3522 - accuracy: 0.4091\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3525 - accuracy: 0.4091\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3524 - accuracy: 0.4091\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 20)                540       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3561 - accuracy: 0.4432\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3559 - accuracy: 0.4432\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3558 - accuracy: 0.4432\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3557 - accuracy: 0.4432\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3560 - accuracy: 0.4432\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3556 - accuracy: 0.4432\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3559 - accuracy: 0.4432\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3556 - accuracy: 0.4432\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3556 - accuracy: 0.4432\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3555 - accuracy: 0.4432\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3555 - accuracy: 0.4432\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3554 - accuracy: 0.4432\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3554 - accuracy: 0.4432\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3552 - accuracy: 0.4432\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3557 - accuracy: 0.4432\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3551 - accuracy: 0.4432\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3551 - accuracy: 0.4432\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3551 - accuracy: 0.4432\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3550 - accuracy: 0.4432\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3551 - accuracy: 0.4432\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3548 - accuracy: 0.4432\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3550 - accuracy: 0.4432\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3547 - accuracy: 0.4432\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.4432\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3548 - accuracy: 0.4432\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3547 - accuracy: 0.4432\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3547 - accuracy: 0.4432\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3548 - accuracy: 0.4432\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.4432\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3546 - accuracy: 0.4432\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3546 - accuracy: 0.4432\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3546 - accuracy: 0.4432\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3546 - accuracy: 0.4318\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.4318\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3546 - accuracy: 0.4318\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.4318\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3543 - accuracy: 0.4318\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3546 - accuracy: 0.4318\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4318\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4318\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4318\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.4318\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3542 - accuracy: 0.4318\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3543 - accuracy: 0.4318\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3543 - accuracy: 0.4318\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.4318\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3540 - accuracy: 0.4318\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3539 - accuracy: 0.4318\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3540 - accuracy: 0.4318\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3543 - accuracy: 0.4318\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4318\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3540 - accuracy: 0.4318\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.4318\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3539 - accuracy: 0.4318\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3539 - accuracy: 0.4318\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3539 - accuracy: 0.4318\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.4318\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3539 - accuracy: 0.4318\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3537 - accuracy: 0.4318\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.4318\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3539 - accuracy: 0.4205\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3537 - accuracy: 0.4205\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3541 - accuracy: 0.4318\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.4318\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3537 - accuracy: 0.4318\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3540 - accuracy: 0.4205\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3535 - accuracy: 0.4091\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3537 - accuracy: 0.4091\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3536 - accuracy: 0.4091\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3536 - accuracy: 0.4205\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3535 - accuracy: 0.4205\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.4205\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3537 - accuracy: 0.4205\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3537 - accuracy: 0.4205\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4091\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4091\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3537 - accuracy: 0.4205\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3533 - accuracy: 0.4205\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3533 - accuracy: 0.4091\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.4205\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.4205\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3533 - accuracy: 0.4205\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3532 - accuracy: 0.4205\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3533 - accuracy: 0.4091\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4205\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.4091\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.4091\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3532 - accuracy: 0.4205\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3532 - accuracy: 0.4205\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3532 - accuracy: 0.4205\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 16)                432       \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 16)                16        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 8)                 8         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637\n",
      "Trainable params: 637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4132 - accuracy: 0.3068\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4130 - accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.3068\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.3068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4130 - accuracy: 0.3068\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4128 - accuracy: 0.3068\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.3068\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.3068\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4127 - accuracy: 0.2955\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4128 - accuracy: 0.2955\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4127 - accuracy: 0.2955\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4128 - accuracy: 0.2955\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4128 - accuracy: 0.2955\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.2955\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4124 - accuracy: 0.2955\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4127 - accuracy: 0.2955\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4124 - accuracy: 0.2955\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4123 - accuracy: 0.2955\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.2955\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4123 - accuracy: 0.2955\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4123 - accuracy: 0.2955\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4124 - accuracy: 0.2955\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4122 - accuracy: 0.2955\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4123 - accuracy: 0.2955\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4122 - accuracy: 0.2955\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4124 - accuracy: 0.2955\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4122 - accuracy: 0.2955\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.2955\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.2955\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4120 - accuracy: 0.2955\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4122 - accuracy: 0.2955\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4122 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4122 - accuracy: 0.2955\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4123 - accuracy: 0.3068\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4121 - accuracy: 0.3068\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.3068\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4121 - accuracy: 0.3068\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4120 - accuracy: 0.3068\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4118 - accuracy: 0.3068\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4115 - accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4114 - accuracy: 0.3068\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4115 - accuracy: 0.3068\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.3068\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4115 - accuracy: 0.3068\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4114 - accuracy: 0.3068\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4117 - accuracy: 0.3068\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4114 - accuracy: 0.3068\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4119 - accuracy: 0.3068\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4114 - accuracy: 0.3068\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4115 - accuracy: 0.3068\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4114 - accuracy: 0.3068\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.33      0.33      0.33         3\n",
      "           3       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.42      0.46      0.44        12\n",
      "weighted avg       0.53      0.58      0.56        12\n",
      "\n",
      "12 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_TEST=[]\n",
    "Y_PRED=[]\n",
    "Y_TEST_got, Y_PRED_got = cascade(X, y_train_one_hot,Y_TEST,Y_PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PRED_t = [item for sublist in Y_PRED_got for item in sublist]\n",
    "Y_TEST_t = [item for sublist in Y_TEST_got for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TEST_ = np.array(Y_TEST_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PRED_ = np.array(Y_PRED_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 0, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_PRED_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TEST_ = rev_one_hot(Y_TEST_)\n",
    "# Y_PRED_ = rev_one_hot(Y_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TEST_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29491, 29491)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_PRED_), len(Y_TEST_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      8906\n",
      "           1       0.74      0.88      0.80      8701\n",
      "           2       0.76      0.60      0.67      5797\n",
      "           3       0.72      0.58      0.64      5871\n",
      "           4       0.00      0.00      0.00       216\n",
      "\n",
      "    accuracy                           0.75     29491\n",
      "   macro avg       0.60      0.58      0.59     29491\n",
      "weighted avg       0.75      0.75      0.74     29491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_TEST_, Y_PRED_)\n",
    "\n",
    "# Plot confusion matrix with colors\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "print(classification_report(Y_TEST_, Y_PRED_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 4.3149 - accuracy: 0.3015\n",
      "Epoch 2/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.4085 - accuracy: 0.3267\n",
      "Epoch 3/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.4001 - accuracy: 0.3342\n",
      "Epoch 4/100\n",
      "6240/6240 [==============================] - 9s 2ms/step - loss: 1.3936 - accuracy: 0.3413\n",
      "Epoch 5/100\n",
      "6240/6240 [==============================] - 9s 2ms/step - loss: 1.3884 - accuracy: 0.3465\n",
      "Epoch 6/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3840 - accuracy: 0.3510\n",
      "Epoch 7/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3804 - accuracy: 0.3543\n",
      "Epoch 8/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3772 - accuracy: 0.3566\n",
      "Epoch 9/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3745 - accuracy: 0.3584\n",
      "Epoch 10/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3720 - accuracy: 0.3596\n",
      "Epoch 11/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3698 - accuracy: 0.3613\n",
      "Epoch 12/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3678 - accuracy: 0.3621\n",
      "Epoch 13/100\n",
      "6240/6240 [==============================] - 9s 2ms/step - loss: 1.3659 - accuracy: 0.3632\n",
      "Epoch 14/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3642 - accuracy: 0.3639\n",
      "Epoch 15/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3627 - accuracy: 0.3645\n",
      "Epoch 16/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3613 - accuracy: 0.3654\n",
      "Epoch 17/100\n",
      "6240/6240 [==============================] - 9s 2ms/step - loss: 1.3599 - accuracy: 0.3663\n",
      "Epoch 18/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3586 - accuracy: 0.3669\n",
      "Epoch 19/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3573 - accuracy: 0.3681\n",
      "Epoch 20/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3562 - accuracy: 0.3682\n",
      "Epoch 21/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3551 - accuracy: 0.3697\n",
      "Epoch 22/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3541 - accuracy: 0.3706\n",
      "Epoch 23/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3530 - accuracy: 0.3712\n",
      "Epoch 24/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3521 - accuracy: 0.3716\n",
      "Epoch 25/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3512 - accuracy: 0.3725\n",
      "Epoch 26/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3502 - accuracy: 0.3731\n",
      "Epoch 27/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3494 - accuracy: 0.3741\n",
      "Epoch 28/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3485 - accuracy: 0.3746\n",
      "Epoch 29/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3476 - accuracy: 0.3758\n",
      "Epoch 30/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3469 - accuracy: 0.3768\n",
      "Epoch 31/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3461 - accuracy: 0.3775\n",
      "Epoch 32/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3453 - accuracy: 0.3788\n",
      "Epoch 33/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3446 - accuracy: 0.3785\n",
      "Epoch 34/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3439 - accuracy: 0.3805\n",
      "Epoch 35/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3431 - accuracy: 0.3813\n",
      "Epoch 36/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3424 - accuracy: 0.3811\n",
      "Epoch 37/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3417 - accuracy: 0.3834\n",
      "Epoch 38/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3411 - accuracy: 0.3846\n",
      "Epoch 39/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3405 - accuracy: 0.3843\n",
      "Epoch 40/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3398 - accuracy: 0.3849\n",
      "Epoch 41/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3392 - accuracy: 0.3860\n",
      "Epoch 42/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3386 - accuracy: 0.3870\n",
      "Epoch 43/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3380 - accuracy: 0.3872\n",
      "Epoch 44/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3374 - accuracy: 0.3879\n",
      "Epoch 45/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3369 - accuracy: 0.3887\n",
      "Epoch 46/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3363 - accuracy: 0.3899\n",
      "Epoch 47/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3357 - accuracy: 0.3901\n",
      "Epoch 48/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3352 - accuracy: 0.3903\n",
      "Epoch 49/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3347 - accuracy: 0.3919\n",
      "Epoch 50/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3342 - accuracy: 0.3932\n",
      "Epoch 51/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.3336 - accuracy: 0.3920\n",
      "Epoch 52/100\n",
      "6240/6240 [==============================] - 11s 2ms/step - loss: 1.3331 - accuracy: 0.3933\n",
      "Epoch 53/100\n",
      "6240/6240 [==============================] - 10s 2ms/step - loss: 1.3326 - accuracy: 0.3945\n",
      "Epoch 54/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3321 - accuracy: 0.3946\n",
      "Epoch 55/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3316 - accuracy: 0.3952\n",
      "Epoch 56/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3311 - accuracy: 0.3953\n",
      "Epoch 57/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3306 - accuracy: 0.3963\n",
      "Epoch 58/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3302 - accuracy: 0.3969\n",
      "Epoch 59/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3297 - accuracy: 0.3979\n",
      "Epoch 60/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3292 - accuracy: 0.3967\n",
      "Epoch 61/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3288 - accuracy: 0.3996\n",
      "Epoch 62/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3283 - accuracy: 0.3989\n",
      "Epoch 63/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3279 - accuracy: 0.3999\n",
      "Epoch 64/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3275 - accuracy: 0.3997\n",
      "Epoch 65/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3271 - accuracy: 0.4006\n",
      "Epoch 66/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3266 - accuracy: 0.4011\n",
      "Epoch 67/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3262 - accuracy: 0.4018\n",
      "Epoch 68/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3258 - accuracy: 0.4019\n",
      "Epoch 69/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3254 - accuracy: 0.4030\n",
      "Epoch 70/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3250 - accuracy: 0.4026\n",
      "Epoch 71/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3246 - accuracy: 0.4036\n",
      "Epoch 72/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3242 - accuracy: 0.4048\n",
      "Epoch 73/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3238 - accuracy: 0.4042\n",
      "Epoch 74/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3234 - accuracy: 0.4041\n",
      "Epoch 75/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3230 - accuracy: 0.4070\n",
      "Epoch 76/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3226 - accuracy: 0.4057\n",
      "Epoch 77/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3222 - accuracy: 0.4060\n",
      "Epoch 78/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3219 - accuracy: 0.4068\n",
      "Epoch 79/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3215 - accuracy: 0.4073\n",
      "Epoch 80/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3211 - accuracy: 0.4077\n",
      "Epoch 81/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3208 - accuracy: 0.4080\n",
      "Epoch 82/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3204 - accuracy: 0.4084\n",
      "Epoch 83/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3200 - accuracy: 0.4098\n",
      "Epoch 84/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3197 - accuracy: 0.4098\n",
      "Epoch 85/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3194 - accuracy: 0.4096\n",
      "Epoch 86/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3190 - accuracy: 0.4107\n",
      "Epoch 87/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3187 - accuracy: 0.4115\n",
      "Epoch 88/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3183 - accuracy: 0.4106\n",
      "Epoch 89/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3180 - accuracy: 0.4120\n",
      "Epoch 90/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3176 - accuracy: 0.4124\n",
      "Epoch 91/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3173 - accuracy: 0.4123\n",
      "Epoch 92/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3170 - accuracy: 0.4131\n",
      "Epoch 93/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3166 - accuracy: 0.4137\n",
      "Epoch 94/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3163 - accuracy: 0.4136\n",
      "Epoch 95/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3160 - accuracy: 0.4150\n",
      "Epoch 96/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3157 - accuracy: 0.4147\n",
      "Epoch 97/100\n",
      "6240/6240 [==============================] - 8s 1ms/step - loss: 1.3154 - accuracy: 0.4154\n",
      "Epoch 98/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3151 - accuracy: 0.4155\n",
      "Epoch 99/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3148 - accuracy: 0.4160\n",
      "Epoch 100/100\n",
      "6240/6240 [==============================] - 9s 1ms/step - loss: 1.3144 - accuracy: 0.4164\n",
      "1560/1560 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 13\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Plot confusion matrix with colors\u001b[39;00m\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(20, input_shape=(26,)),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(10),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(5, activation='softmax')  # Assuming num_classes output classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_one_hot, test_size=0.2, random_state=42)\n",
    "model.fit(X_train,y_train, epochs=100, batch_size=32)\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = rev_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.65      0.55     12975\n",
      "           1       0.47      0.19      0.27     12021\n",
      "           2       0.39      0.50      0.44     12188\n",
      "           3       0.35      0.33      0.34     12132\n",
      "           4       0.00      0.00      0.00       604\n",
      "\n",
      "    accuracy                           0.42     49920\n",
      "   macro avg       0.34      0.33      0.32     49920\n",
      "weighted avg       0.42      0.42      0.40     49920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aaditya Gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predicted_label)\n",
    "\n",
    "# Plot confusion matrix with colors\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "print(classification_report(y_test,predicted_label ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
